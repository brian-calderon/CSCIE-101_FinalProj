% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames,x11names}{xcolor}
%
\documentclass[
  letterpaper,
  DIV=11,
  numbers=noendperiod]{scrartcl}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage[margin=1.3cm]{geometry}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\makeatletter
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}{
    \@ifstar
      \xxxParagraphStar
      \xxxParagraphNoStar
  }
  \newcommand{\xxxParagraphStar}[1]{\oldparagraph*{#1}\mbox{}}
  \newcommand{\xxxParagraphNoStar}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}{
    \@ifstar
      \xxxSubParagraphStar
      \xxxSubParagraphNoStar
  }
  \newcommand{\xxxSubParagraphStar}[1]{\oldsubparagraph*{#1}\mbox{}}
  \newcommand{\xxxSubParagraphNoStar}[1]{\oldsubparagraph{#1}\mbox{}}
\fi
\makeatother

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
% definitions for citeproc citations
\NewDocumentCommand\citeproctext{}{}
\NewDocumentCommand\citeproc{mm}{%
  \begingroup\def\citeproctext{#2}\cite{#1}\endgroup}
\makeatletter
 % allow citations to break across lines
 \let\@cite@ofmt\@firstofone
 % avoid brackets around text for \cite:
 \def\@biblabel#1{}
 \def\@cite#1#2{{#1\if@tempswa , #2\fi}}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newenvironment{CSLReferences}[2] % #1 hanging-indent, #2 entry-spacing
 {\begin{list}{}{%
  \setlength{\itemindent}{0pt}
  \setlength{\leftmargin}{0pt}
  \setlength{\parsep}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
   \setlength{\leftmargin}{\cslhangindent}
   \setlength{\itemindent}{-1\cslhangindent}
  \fi
  % set entry spacing
  \setlength{\itemsep}{#2\baselineskip}}}
 {\end{list}}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{\hfill\break\parbox[t]{\linewidth}{\strut\ignorespaces#1\strut}}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{\strut#1\strut}}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{ragged2e}
\justifying
\KOMAoption{captions}{tableheading}
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother

\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage{bookmark}

\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={HARVARD EXTENSION SCHOOL},
  pdfauthor={Author: Dinesh Bedathuru; Author: Brian Calderon; Author: Jeisson Hernandez; Author: Hao Fu; Author: Derek Rush; Author: Jeremy Tajonera; Author: Catherine Tully},
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={Blue},
  pdfcreator={LaTeX via pandoc}}


\title{HARVARD EXTENSION SCHOOL}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{% add subtitle to \maketitle
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{EXT CSCI E-106 Model Data Class Group Project Template}
\author{Author: Dinesh Bedathuru \and Author: Brian
Calderon \and Author: Jeisson Hernandez \and Author: Hao Fu \and Author:
Derek Rush \and Author: Jeremy Tajonera \and Author: Catherine Tully}
\date{09 May 2025}

\begin{document}
\maketitle
\begin{abstract}
In this project, our aim is to classify the probability of a passenger
surviving the Titanic crash of 1912. We used a variety of linear and
non-linear models to deduce the most accurate model and provide
long-term stability in our predictions.
\end{abstract}

\renewcommand*\contentsname{Table of contents}
{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables

Classify whether a passenger on board the maiden voyage of the RMS
Titanic in 1912 survived given their age, sex and class.
Sample-Data-Titanic-Survival.csv to be used in the Final Project

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Variable
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Description
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
pclass & \textbf{Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)} \\
survived & \textbf{Survival (0 = No; 1 = Yes)} \\
name & \textbf{Name} \\
sex & \textbf{Sex} \\
age & \textbf{Age} \\
sibsp & \textbf{\# of siblings / spouses aboard the Titanic} \\
parch & \textbf{\# of parents / children aboard the Titanic} \\
ticket & \textbf{Ticket number} \\
fare & \textbf{Passenger fare} \\
cabin & \textbf{Cabin number} \\
embarked & \textbf{Port of Embarkation (C = Cherbourg; Q = Queenstown; S
= Southampton)} \\
boat & \textbf{Lifeboat ID, if passenger survived} \\
body & \textbf{Body number (if passenger did not survive and body was
recovered} \\
home.dest & \textbf{The intended home destination of the passenger} \\
\end{longtable}

\section{Instructions:}\label{instructions}

0. Join a team with your fellow students with appropriate size (Up to
Nine Students total) If you have not group by the end of the week of
April 11 you may present the project by yourself or I will randomly
assign other stranded student to your group. I will let know the final
groups in April 11.

1. Load and Review the dataset named ``Titanic\_Survival\_Data.csv'' 2.
Create the train data set which contains 70\% of the data and use
set.seed (15). The remaining 30\% will be your test data set.

3. Investigate the data and combine the level of categorical variables
if needed and drop variables as needed. For example, you can drop id,
Latitude, Longitude, etc.

4. Build appropriate model to predict the probability of survival.

5. Create scatter plots and a correlation matrix for the train data set.
Interpret the possible relationship between the response.

6. Build the best models by using the appropriate selection method.
Compare the performance of the best logistic linear models.

7. Make sure that model assumption(s) are checked for the final model.
Apply remedy measures (transformation, etc.) that helps satisfy the
assumptions.

8. Investigate unequal variances and multicollinearity.

9. Build an alternative to your model based on one of the following
approaches as applicable to predict the probability of survival:
logistic regression, classification Tree, NN, or SVM. Check the
applicable model assumptions. Explore using a negative binomial
regression and a Poisson regression.

10. Use the test data set to assess the model performances from above.

11. Based on the performances on both train and test data sets,
determine your primary (champion) model and the other model which would
be your benchmark model.

12. Create a model development document that describes the model
following this template, input the name of the authors, Harvard IDs, the
name of the Group, all of your code and calculations, etc..

\textbf{Due Date: May 12 2025 1159 pm hours EST Notes No typographical
errors, grammar mistakes, or misspelled words, use English language All
tables need to be numbered and describe their content in the body of the
document All figures/graphs need to be numbered and describe their
content All results must be accurate and clearly explained for a casual
reviewer to fully understand their purpose and impact Submit both the
RMD markdown file and PDF with the sections with appropriate
explanations. A more formal.}

\section{Executive Summary}\label{executive-summary}

This section will describe the model usage, your conclusions and any
regulatory and internal requirements. In a real world scenario, this
section is for senior management who do not need to know the details.
They need to know high level (the purpose of the model, limitations of
the model and any issues).

\section{Introduction}\label{introduction}

This section needs to introduce the reader to the problem to be
resolved, the purpose, and the scope of the statistical testing applied.
What you are doing with your prediction? What is the purpose of the
model? What methods were trained on the data, how large is the test
sample, and how did you build the model?

The Titanic was a British-registered ship that set sail on its maiden
voyage on April 10th, 1912 with 2,240 passengers and crew on board. On
April 15th, 1912, the ship struck an iceberg, split in half, and sank to
the bottom of the ocean (National Oceanic and Atmospheric Administration
(NOAA), 2023). In this report, we are going to analyze the data in the
Titanic.csv file and use it to determine the best model for predicting
whether someone on board would live or die. By creating this model, we
hope to understand what factors a passenger could have taken into
account in order to reduce their risk of death during the trip. We
cleaned the data and split into into a train/test split in order to
properly train our models. We created simple linear models, multivariate
linear models, logistic models (both binomial and poisson), a regression
tree, and a neural network model. The train sample size was 916 data
points (70.03\%) and the test sample size was 392 data points (29.97\%).
We built the models after examining the data and determining which
predictor variables we thought would be most relevant for survival rate.
Once we had our variables and training data, we created the models and
examined the performance of the models on both training and testing data
to determine if they were robust. We also examined if the model
assumptions appeared to hold for each model.

\section{Description of the data and
quality}\label{description-of-the-data-and-quality}

Based on the data cleaning we were able to only remove 2 rows from the
data set. We used median imputation as well as KNN for various columns.
We also dummified several categorical columns. We found that leaving
sibsp and parch as continuous as opposed to categorical increased their
contributions to the model performance (See
\hyperref[appendix_A]{Appendix A}). Further, we also extracted the deck
number and found that removing deck\_G from the model increased its
performance.

\subsection{Loading the data}\label{loading-the-data}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{odata }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"../data/Titanic\_Survival\_Data.csv"}\NormalTok{)}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Size of entire data set:"}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(odata), }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Size of entire data set: 1310 
\end{verbatim}

\subsection{Removing un-needed
columns}\label{removing-un-needed-columns}

Name: Removing because names have no inference on surivival (inference)

ticket: Ticket No.~will also likely not have an influence in survival

boat: This is highly correlated to the survival dependant variable since
people who made it on a boat likely survived

body: This is highly correlated to the survival dependant variable since
people who's body was recovered did not survive.

home.dest: The destination likely has nothing to do with the survival

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data.clean }\OtherTok{=}\NormalTok{ odata[, }\SpecialCharTok{!}\NormalTok{(}\FunctionTok{names}\NormalTok{(odata) }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"name"}\NormalTok{, }\StringTok{"ticket"}\NormalTok{, }\StringTok{"boat"}\NormalTok{,}\StringTok{"body"}\NormalTok{,}\StringTok{"home.dest"}\NormalTok{))]}
\end{Highlighting}
\end{Shaded}

\subsection{Data Augmentation}\label{data-augmentation}

We extracted the deck letter from the cabin since it could potentially
correlate to the survival.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Extract deck letter from cabin}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{substr}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{cabin, }\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\CommentTok{\# Remove cabin col:}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{cabin }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\end{Highlighting}
\end{Shaded}

\subsection{Initial Check for Missing
values}\label{initial-check-for-missing-values}

We see that age and deck have the most amount of missing data, therefore
we proceed to impute them.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{print}\NormalTok{(}\FunctionTok{plot\_missing\_barchart}\NormalTok{(data.clean))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-4-1.pdf}

}

\caption{Percentage of Missing Values}

\end{figure}%

\subsection{Imputing data}\label{imputing-data}

Below we impute Age using the median value in that column.

For deck we use KNN to impute the missing deck values.

After imputing these two columns we can see that the largest amount of
missing data is \textasciitilde0.2\% which is quite small and can be
removed.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# {-}{-}{-}{-} Age{-}{-}{-}{-}}
\CommentTok{\#Replace NAs in age column with Median value }
\NormalTok{median\_age }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{age, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{data.clean }\OtherTok{\textless{}{-}}\NormalTok{ data.clean }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{age =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(age), median\_age, age))}

\CommentTok{\# {-}{-}{-}{-} deck{-}{-}{-}{-}}
\CommentTok{\# For deck, since its a category, we decided to use KNN  to impute the column:}

\CommentTok{\# Install if not already installed}
\CommentTok{\# install.packages("VIM")}
\FunctionTok{library}\NormalTok{(VIM)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading required package: colorspace
\end{verbatim}

\begin{verbatim}
Loading required package: grid
\end{verbatim}

\begin{verbatim}
VIM is ready to use.
\end{verbatim}

\begin{verbatim}
Suggestions and bug-reports can be submitted at: https://github.com/statistikat/VIM/issues
\end{verbatim}

\begin{verbatim}

Attaching package: 'VIM'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:datasets':

    sleep
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Replace "" with NA in the \textquotesingle{}deck\textquotesingle{} column}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck[data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{""}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NA}

\CommentTok{\# Convert \textquotesingle{}cabin\textquotesingle{} to factor}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck)}

\CommentTok{\# Apply kNN imputation just to Cabin column}
\NormalTok{data.clean }\OtherTok{\textless{}{-}} \FunctionTok{kNN}\NormalTok{(data.clean, }\AttributeTok{variable =} \StringTok{"deck"}\NormalTok{, }\AttributeTok{k =} \DecValTok{5}\NormalTok{)}

\CommentTok{\# Check that NAs were imputed}
\CommentTok{\# sum(is.na(data.clean$deck))        \# Original}
\CommentTok{\# sum(is.na(data.clean.imputed$deck)) \# After}

\CommentTok{\# Remove indicator col:}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_imp }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#          Check for Missing values after Imputation                           \#}
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}

\FunctionTok{plot\_missing\_barchart}\NormalTok{(data.clean)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-6-1.pdf}

}

\caption{Percentage of Missing Values after Imputation}

\end{figure}%

\subsection{Dummifying Columns:}\label{dummifying-columns}

We dummify pclass, sex, embarked and deck. We leave sibsp and parch as
continuous variables as we observed that dummifying these columns leads
to smaller significance (See \hyperref[appendix_A]{Appendix A}), whilst
leaving them as continuous maximizes their contributions to the models
explanatory power.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Dummifying pclass:}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{pclass\_1 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{pclass }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{pclass\_2 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{pclass }\SpecialCharTok{==} \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying sex:}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{sex\_M }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{sex }\SpecialCharTok{==} \StringTok{\textquotesingle{}male\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying embarked:}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{embarked\_C }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{embarked }\SpecialCharTok{==} \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{embarked\_Q }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{embarked }\SpecialCharTok{==} \StringTok{\textquotesingle{}Q\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying deck:}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_A }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_B }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_C }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_D }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_E }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_F }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean}\SpecialCharTok{$}\NormalTok{deck\_G }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}G\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Removing Dummified cols:}
\NormalTok{data.clean }\OtherTok{=} \FunctionTok{subset}\NormalTok{(data.clean, }\AttributeTok{select  =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(pclass, sex, embarked,deck))}
\end{Highlighting}
\end{Shaded}

\subsection{Remove NA rows and deck\_G}\label{remove-na-rows-and-deck_g}

Below we remove NA rows, which turned out to be only 2 after proper
cleaning and imputation. We also removed deck\_G as we observed that it
has a large skew in the data distribution with only 13 people allocated
in this deck. It was observed that this variable lead to erroneous
predictions in the model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plot histogram of the \textquotesingle{}values\textquotesingle{} column}
\FunctionTok{hist}\NormalTok{(data.clean}\SpecialCharTok{$}\NormalTok{deck\_G,}
     \AttributeTok{main =} \StringTok{"Histogram of Values"}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Values"}\NormalTok{,}
     \AttributeTok{col =} \StringTok{"skyblue"}\NormalTok{,}
     \AttributeTok{border =} \StringTok{"white"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\caption{Histogram of Deck\_G}

\end{figure}%

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Removing deck\_G col:}
\NormalTok{data.clean }\OtherTok{=} \FunctionTok{subset}\NormalTok{(data.clean, }\AttributeTok{select  =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(deck\_G))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data.clean }\OtherTok{=} \FunctionTok{na.omit}\NormalTok{(data.clean)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(odata) }\SpecialCharTok{{-}} \FunctionTok{nrow}\NormalTok{(data.clean),}\StringTok{\textquotesingle{}rows were removed from original dataset\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
2 rows were removed from original dataset
\end{verbatim}

\subsection{Divide into Test / Train}\label{divide-into-test-train}

Finally we divide into 70\% training data and 30\% test data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{ (}\DecValTok{1023}\NormalTok{)}
\NormalTok{train\_indices }\OtherTok{=} \FunctionTok{sample}\NormalTok{(}\DecValTok{1} \SpecialCharTok{:} \FunctionTok{nrow}\NormalTok{(data.clean), }\AttributeTok{size =} \FloatTok{0.7005}\SpecialCharTok{*}\FunctionTok{nrow}\NormalTok{(data.clean), }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{train }\OtherTok{=}\NormalTok{ data.clean[train\_indices,]}
\NormalTok{test }\OtherTok{=}\NormalTok{ data.clean[}\SpecialCharTok{{-}}\NormalTok{train\_indices,]}
\FunctionTok{cat}\NormalTok{(}\StringTok{"We are using:"}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(train)}\SpecialCharTok{/}\FunctionTok{nrow}\NormalTok{(data.clean) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\StringTok{\textquotesingle{}\% of the data for training\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
We are using: 70.03058 % of the data for training
\end{verbatim}

\subsection{EDA}\label{eda}

Using the training data set we use a variety of method to draw some
initial conclusions:

\begin{itemize}
\tightlist
\item
  Histogram: Showing that more people in their late teens up to late
  thirties survived.
\item
  Bar chart showing that more people died than survived
\item
  Bar chart showing that a higher number of people survived when they
  had less siblings on board.
\item
  Correlation matrix shows that sex and Deck\_F are highly negatively
  correlated to survival. There is a soft positive correlation to
  pclass\_1.
\item
  There is a high correlation between pclass\_1 and fare, this justifies
  that one of these predictors can potentially be removed.
\item
  The scatter plots did not give us much more information on the
  relation between the predictors and the dependent variable.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Histogram showing that more people in their late teens up to late thirties survived.}
\FunctionTok{ggplot}\NormalTok{(train, }\FunctionTok{aes}\NormalTok{(age)) }\SpecialCharTok{+}
  \FunctionTok{geom\_histogram}\NormalTok{(}\AttributeTok{bins=}\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-11-1.pdf}

}

\caption{Histogram of survival vs age}

\end{figure}%

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Bar chart showing that more people died than survived}
\FunctionTok{ggplot}\NormalTok{(train, }\FunctionTok{aes}\NormalTok{(survived)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-12-1.pdf}

}

\caption{Barchart of survival}

\end{figure}%

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Bar chart showing that a higher number of people survived when they had less }
\CommentTok{\# siblings on board.}
\FunctionTok{ggplot}\NormalTok{(train, }\FunctionTok{aes}\NormalTok{(sibsp, survived)) }\SpecialCharTok{+}
  \FunctionTok{geom\_bar}\NormalTok{(}\AttributeTok{stat=}\StringTok{\textquotesingle{}identity\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-13-1.pdf}

}

\caption{Barchart of survival vs Num. of siblings}

\end{figure}%

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(train)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
              survived         age        sibsp        parch        fare
survived    1.00000000 -0.04599216 -0.027543645  0.095720424  0.24962042
age        -0.04599216  1.00000000 -0.154952394 -0.122885529  0.16447722
sibsp      -0.02754365 -0.15495239  1.000000000  0.355216328  0.16529618
parch       0.09572042 -0.12288553  0.355216328  1.000000000  0.20987827
fare        0.24962042  0.16447722  0.165296185  0.209878267  1.00000000
pclass_1    0.28432063  0.34847627 -0.022306615 -0.016451014  0.59116304
pclass_2    0.06118909  0.01898825 -0.069089243 -0.017696720 -0.12563735
sex_M      -0.53377358  0.05385130 -0.127066747 -0.243501842 -0.20177640
embarked_C  0.14757622  0.05701305 -0.061215242 -0.001165488  0.27208779
embarked_Q -0.02542950 -0.03373092 -0.060221066 -0.093253422 -0.12699238
deck_A      0.03351255  0.11849174 -0.066920639 -0.057789108  0.05775137
deck_B      0.16163293  0.11668084 -0.018056185  0.073894445  0.45996364
deck_C      0.16746961  0.15595995  0.026704925 -0.051690185  0.30933961
deck_D      0.09857507  0.04928304 -0.005406569 -0.019083135  0.01011501
deck_E      0.32212013  0.15182289 -0.084456592 -0.036003896 -0.01993646
deck_F     -0.47931430 -0.28802595  0.064953732  0.028147672 -0.41755468
              pclass_1     pclass_2       sex_M   embarked_C  embarked_Q
survived    0.28432063  0.061189091 -0.53377358  0.147576220 -0.02542950
age         0.34847627  0.018988253  0.05385130  0.057013047 -0.03373092
sibsp      -0.02230662 -0.069089243 -0.12706675 -0.061215242 -0.06022107
parch      -0.01645101 -0.017696720 -0.24350184 -0.001165488 -0.09325342
fare        0.59116304 -0.125637353 -0.20177640  0.272087792 -0.12699238
pclass_1    1.00000000 -0.302550060 -0.11706927  0.285611052 -0.16373859
pclass_2   -0.30255006  1.000000000 -0.01057862 -0.143425262 -0.14105035
sex_M      -0.11706927 -0.010578622  1.00000000 -0.040151739 -0.09800681
embarked_C  0.28561105 -0.143425262 -0.04015174  1.000000000 -0.16362864
embarked_Q -0.16373859 -0.141050354 -0.09800681 -0.163628636  1.00000000
deck_A      0.28591131 -0.084644694  0.05358941  0.185442366 -0.05946853
deck_B      0.43224693 -0.122902623 -0.09558575  0.185963991 -0.08030780
deck_C      0.48474445 -0.077533075 -0.09364506  0.172425379 -0.07946766
deck_D      0.13502549  0.038571996 -0.05947357  0.269688905 -0.09069030
deck_E      0.05159522 -0.006826092 -0.06575988 -0.108208463 -0.08986794
deck_F     -0.70753043  0.136114513  0.15216823 -0.325659369  0.22529873
                deck_A      deck_B      deck_C       deck_D       deck_E
survived    0.03351255  0.16163293  0.16746961  0.098575075  0.322120129
age         0.11849174  0.11668084  0.15595995  0.049283037  0.151822887
sibsp      -0.06692064 -0.01805619  0.02670493 -0.005406569 -0.084456592
parch      -0.05778911  0.07389444 -0.05169019 -0.019083135 -0.036003896
fare        0.05775137  0.45996364  0.30933961  0.010115010 -0.019936462
pclass_1    0.28591131  0.43224693  0.48474445  0.135025488  0.051595219
pclass_2   -0.08464469 -0.12290262 -0.07753308  0.038571996 -0.006826092
sex_M       0.05358941 -0.09558575 -0.09364506 -0.059473565 -0.065759880
embarked_C  0.18544237  0.18596399  0.17242538  0.269688905 -0.108208463
embarked_Q -0.05946853 -0.08030780 -0.07946766 -0.090690296 -0.089867941
deck_A      1.00000000 -0.04730303 -0.06177894 -0.053418545 -0.066980420
deck_B     -0.04730303  1.00000000 -0.08342784 -0.072137753 -0.090452052
deck_C     -0.06177894 -0.08342784  1.00000000 -0.094213702 -0.118132634
deck_D     -0.05341854 -0.07213775 -0.09421370  1.000000000 -0.102146031
deck_E     -0.06698042 -0.09045205 -0.11813263 -0.102146031  1.000000000
deck_F     -0.23206097 -0.31338100 -0.40928339 -0.353896063 -0.443743031
                deck_F
survived   -0.47931430
age        -0.28802595
sibsp       0.06495373
parch       0.02814767
fare       -0.41755468
pclass_1   -0.70753043
pclass_2    0.13611451
sex_M       0.15216823
embarked_C -0.32565937
embarked_Q  0.22529873
deck_A     -0.23206097
deck_B     -0.31338100
deck_C     -0.40928339
deck_D     -0.35389606
deck_E     -0.44374303
deck_F      1.00000000
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{pairs}\NormalTok{(train[}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{13}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-14-1.pdf}

}

\caption{Scatter plots of all variables in train data}

\end{figure}%

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Since this data is mainly categorical, the scatterplot and correlation matrix are not very useful.}
\end{Highlighting}
\end{Shaded}

(Statology, 2025) is used to develop the correlation values between our
categorical columns. This describes the use of pysch and rcompanion.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("psych")}
\FunctionTok{library}\NormalTok{(psych) }\CommentTok{\# [@statology2025] to understand how this works}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Attaching package: 'psych'
\end{verbatim}

\begin{verbatim}
The following objects are masked from 'package:ggplot2':

    %+%, alpha
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tetrachoric}\NormalTok{(train[, }\FunctionTok{c}\NormalTok{(}\StringTok{"survived"}\NormalTok{, }\StringTok{"sex\_M"}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Call: tetrachoric(x = train[, c("survived", "sex_M")])
tetrachoric correlation 
         srvvd sex_M
survived  1.00      
sex_M    -0.75  1.00

 with tau of 
survived    sex_M 
    0.26    -0.35 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tetrachoric}\NormalTok{(train[, }\FunctionTok{c}\NormalTok{(}\StringTok{"survived"}\NormalTok{, }\StringTok{"pclass\_1"}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Call: tetrachoric(x = train[, c("survived", "pclass_1")])
tetrachoric correlation 
         srvvd pcl_1
survived 1.00       
pclass_1 0.46  1.00 

 with tau of 
survived pclass_1 
    0.26     0.69 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{tetrachoric}\NormalTok{(train[, }\FunctionTok{c}\NormalTok{(}\StringTok{"survived"}\NormalTok{, }\StringTok{"pclass\_2"}\NormalTok{)])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Call: tetrachoric(x = train[, c("survived", "pclass_2")])
tetrachoric correlation 
         srvvd pcl_2
survived 1.00       
pclass_2 0.11  1.00 

 with tau of 
survived pclass_2 
    0.26     0.77 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#install.packages("rcompanion")}
\FunctionTok{library}\NormalTok{(rcompanion) }\CommentTok{\# Reference 4 to understand how this works.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Attaching package: 'rcompanion'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:psych':

    phi
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cramerV}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{survived, train}\SpecialCharTok{$}\NormalTok{sex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Cramer V 
  0.5338 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(corrplot)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
corrplot 0.95 loaded
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{cor\_matrix }\OtherTok{\textless{}{-}} \FunctionTok{cor}\NormalTok{(train)}\CommentTok{\#[,1]}
\FunctionTok{corrplot}\NormalTok{(cor\_matrix, }\AttributeTok{method =} \StringTok{"circle"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-16-1.pdf}

}

\caption{Correlation Matrix}

\end{figure}%

\section{Model Development Process}\label{model-development-process}

The data was properly cleaned and divided into train/test in the prior
section.

Here we train a binary model. The Q-Q plot shows that the residuals are
indeed normally distributed so a transformation is potentially not
necessary.

The statistical comparison between test and train data shows that the
model is very stable with an accuracy of \textasciitilde84\% for both.

We also analyzed the VIF and we see that there is high degree of
correlation between the decks, this provides justification to remove
some of the decks as predictors.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(car)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Loading required package: carData
\end{verbatim}

\begin{verbatim}

Attaching package: 'car'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:psych':

    logit
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:dplyr':

    recode
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:purrr':

    some
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Log model on train data:}
\NormalTok{lmod }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train)}
\CommentTok{\# summary(lmod)}
\FunctionTok{vif}\NormalTok{(lmod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       age      sibsp      parch       fare   pclass_1   pclass_2      sex_M 
  1.525578   1.241394   1.293316   1.718545   4.501868   1.540346   1.608259 
embarked_C embarked_Q     deck_A     deck_B     deck_C     deck_D     deck_E 
  1.484871   1.397384   5.486232   5.989183   9.392249   8.038956   8.173562 
    deck_F 
 18.354762 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_hat\_log\_train }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lmod, }\AttributeTok{data =}\NormalTok{ train, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions\_log\_train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_log\_train }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{y\_hat\_log\_test}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(lmod, }\AttributeTok{newdata =}\NormalTok{ test, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions\_log\_test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_log\_test }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{confusion\_matrix\_log\_train }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_log\_train), }\FunctionTok{as.factor}\NormalTok{(train}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{base.model.accuracy }\OtherTok{=}\NormalTok{ confusion\_matrix\_log\_train}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{base.model.f1 }\OtherTok{=}\NormalTok{ confusion\_matrix\_log\_train}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{base.model.train.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ base.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ base.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(base.model.train.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}base.model.train\textquotesingle{}}  



\NormalTok{confusion\_matrix\_log\_test }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_log\_test), }\FunctionTok{as.factor}\NormalTok{(test}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{base.model.accuracy }\OtherTok{=}\NormalTok{ confusion\_matrix\_log\_test}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{base.model.f1 }\OtherTok{=}\NormalTok{ confusion\_matrix\_log\_test}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{base.model.test.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ base.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ base.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(base.model.test.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}base.model.test\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(base.model.train.summary, base.model.test.summary))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrr@{}}
\caption{Summary Stats. of base log. model}\tabularnewline
\toprule\noalign{}
& Accuracy & F1 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& Accuracy & F1 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
base.model.train & 0.8482533 & 0.8093278 \\
base.model.test & 0.8443878 & 0.7829181 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(lmod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = survived ~ ., family = binomial, data = train)

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  5.412e+00  8.945e-01   6.050 1.45e-09 ***
age         -5.725e-02  9.037e-03  -6.335 2.37e-10 ***
sibsp       -2.434e-01  1.199e-01  -2.030  0.04232 *  
parch        2.348e-02  1.181e-01   0.199  0.84239    
fare         4.969e-05  2.301e-03   0.022  0.98277    
pclass_1     1.012e+00  4.589e-01   2.206  0.02741 *  
pclass_2     1.765e+00  2.973e-01   5.939 2.87e-09 ***
sex_M       -3.265e+00  2.557e-01 -12.768  < 2e-16 ***
embarked_C   7.810e-01  2.916e-01   2.678  0.00740 ** 
embarked_Q   8.999e-01  3.639e-01   2.473  0.01340 *  
deck_A      -2.136e+00  1.004e+00  -2.128  0.03338 *  
deck_B      -1.587e+00  1.013e+00  -1.567  0.11708    
deck_C      -1.874e+00  9.535e-01  -1.965  0.04940 *  
deck_D      -2.644e+00  9.259e-01  -2.856  0.00429 ** 
deck_E       2.530e-01  8.911e-01   0.284  0.77646    
deck_F      -4.351e+00  8.584e-01  -5.069 4.01e-07 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1230.15  on 915  degrees of freedom
Residual deviance:  634.33  on 900  degrees of freedom
AIC: 666.33

Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\FunctionTok{plot}\NormalTok{(lmod)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-21-1.pdf}

}

\caption{4x4 standard plots for log. model}

\end{figure}%

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Plots show that a linear model is not appropriate for this data.}
\end{Highlighting}
\end{Shaded}

\section{Model Performance Testing}\label{model-performance-testing}

We compare four different models: 1) Base log. model 2) Model with
insig. pred. removed 3) Stepwise model 4) Model with high vif pred.
removed

When comparing the accuracy and F1 score on all models the base model
was still the highest performer and we decided to use that as the
champion model until now.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#              Function to remove Insig. Predictors one by one                 \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}

\NormalTok{backward\_eliminate }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(model, }\AttributeTok{alpha =} \FloatTok{0.05}\NormalTok{) \{}
  \ControlFlowTok{repeat}\NormalTok{ \{}
\NormalTok{    d1 }\OtherTok{=} \FunctionTok{drop1}\NormalTok{(model, }\AttributeTok{test =} \StringTok{"F"}\NormalTok{)}
    
    \CommentTok{\# Get p{-}values excluding intercept row}
\NormalTok{    pvals }\OtherTok{=}\NormalTok{ d1}\SpecialCharTok{$}\StringTok{\textasciigrave{}}\AttributeTok{Pr(\textgreater{}F)}\StringTok{\textasciigrave{}}\NormalTok{[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]}
    
    \CommentTok{\# Stop if all predictors are significant or only intercept left}
    \ControlFlowTok{if}\NormalTok{( }\FunctionTok{all}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(pvals)) }\SpecialCharTok{||} \FunctionTok{max}\NormalTok{(pvals, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{\textless{}=}\NormalTok{ alpha )\{}
      \FunctionTok{print}\NormalTok{(}\StringTok{"all variable are signifcant"}\NormalTok{)}
      \ControlFlowTok{break}
\NormalTok{    \} }
    
    \CommentTok{\# Remove the term with max p{-}value}
\NormalTok{    term\_to\_remove }\OtherTok{=} \FunctionTok{rownames}\NormalTok{(d1)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{][}\FunctionTok{which.max}\NormalTok{(pvals)]}
    \FunctionTok{cat}\NormalTok{(}\StringTok{"Removing:"}\NormalTok{, term\_to\_remove, }\StringTok{"with p{-}value"}\NormalTok{, }\FunctionTok{max}\NormalTok{(pvals, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{), }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    model }\OtherTok{=} \FunctionTok{update}\NormalTok{(model, }\FunctionTok{paste}\NormalTok{(}\StringTok{". \textasciitilde{} . {-}"}\NormalTok{, term\_to\_remove))}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(model)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                     Function to remove Cooks Outliers                        \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#                        }
\CommentTok{\# model\_formula: A formula object, e.g. PSA.level \textasciitilde{} .}
\CommentTok{\# data: A data frame containing the variables in the model.}
\CommentTok{\# threshold: A numeric value indicating the Cook\textquotesingle{}s D threshold (default 0.5).}
\CommentTok{\# print: If TRUE (default) will print the rows beign removed.}
\CommentTok{\# returns: A list with the final model and the filtered dataset.}
\CommentTok{\# }
\CommentTok{\# Example usage:}
\CommentTok{\# result = remove\_cooks\_outliers(PSA.level \textasciitilde{} ., mydata)}
\CommentTok{\# summary(result$model)}
\CommentTok{\# str(result$filtered\_data)}
\NormalTok{remove\_cooks\_outliers }\OtherTok{=} \ControlFlowTok{function}\NormalTok{(model\_formula, data, }\AttributeTok{threshold =} \FloatTok{0.5}\NormalTok{, }
                                 \AttributeTok{print =} \ConstantTok{TRUE}\NormalTok{) }
\NormalTok{  \{}
  
\NormalTok{  all\_high\_cd\_rows }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{()  }\CommentTok{\# to store all removed rows}

  \ControlFlowTok{repeat}\NormalTok{ \{}
\NormalTok{    model }\OtherTok{=} \FunctionTok{glm}\NormalTok{(model\_formula, }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ data) }
\NormalTok{    cooksD }\OtherTok{=} \FunctionTok{cooks.distance}\NormalTok{(model)}
\NormalTok{    high\_cd\_indices }\OtherTok{=} \FunctionTok{which}\NormalTok{(cooksD }\SpecialCharTok{\textgreater{}}\NormalTok{ threshold)}
    
    \ControlFlowTok{if}\NormalTok{ (}\FunctionTok{length}\NormalTok{(high\_cd\_indices) }\SpecialCharTok{==} \DecValTok{0}\NormalTok{) \{ }\CommentTok{\# If there are no more outliers}
      \ControlFlowTok{break}
\NormalTok{    \}}
    
    \ControlFlowTok{if}\NormalTok{ (print }\SpecialCharTok{==} \ConstantTok{TRUE}\NormalTok{)\{}
      \FunctionTok{cat}\NormalTok{(}\StringTok{"Removing rows with Cook\textquotesingle{}s D \textgreater{}"}\NormalTok{, threshold, }\StringTok{":}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{, high\_cd\_indices, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\NormalTok{    \}}
    \CommentTok{\# Save these outliers before removing them}
\NormalTok{    high\_cd\_rows }\OtherTok{=}\NormalTok{ data[high\_cd\_indices, ]}
\NormalTok{    all\_high\_cd\_rows }\OtherTok{=} \FunctionTok{rbind}\NormalTok{(all\_high\_cd\_rows, high\_cd\_rows)}
    
    \CommentTok{\# Update data by removing high CD rows for next iteration.}
\NormalTok{    data }\OtherTok{=}\NormalTok{ data[}\SpecialCharTok{{-}}\NormalTok{high\_cd\_indices, ]}
\NormalTok{  \}}
  
\NormalTok{  final\_model }\OtherTok{=} \FunctionTok{glm}\NormalTok{(model\_formula, }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ data)}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{model =}\NormalTok{ final\_model, }\AttributeTok{filtered\_data =}\NormalTok{ data, }\AttributeTok{high\_cd\_data =}\NormalTok{ all\_high\_cd\_rows))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                    Model with insig. variables removed                      \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\NormalTok{binary.model.filtered }\OtherTok{=} \FunctionTok{backward\_eliminate}\NormalTok{(lmod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in drop1.glm(model, test = "F"): F test assumes 'quasibinomial' family
\end{verbatim}

\begin{verbatim}
Removing: fare with p-value 0.979474 
\end{verbatim}

\begin{verbatim}
Warning in drop1.glm(model, test = "F"): F test assumes 'quasibinomial' family
\end{verbatim}

\begin{verbatim}
Removing: parch with p-value 0.8042413 
\end{verbatim}

\begin{verbatim}
Warning in drop1.glm(model, test = "F"): F test assumes 'quasibinomial' family
\end{verbatim}

\begin{verbatim}
Removing: deck_E with p-value 0.7522959 
\end{verbatim}

\begin{verbatim}
Warning in drop1.glm(model, test = "F"): F test assumes 'quasibinomial' family
\end{verbatim}

\begin{verbatim}
[1] "all variable are signifcant"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                step wise model with insig. variables removed                 \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\FunctionTok{library}\NormalTok{(olsrr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Attaching package: 'olsrr'
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:MASS':

    cement
\end{verbatim}

\begin{verbatim}
The following object is masked from 'package:datasets':

    rivers
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ols\_step\_both\_p}\NormalTok{(lmod,}\AttributeTok{p\_enter=}\FloatTok{0.1}\NormalTok{,}\AttributeTok{p\_remove=}\FloatTok{0.05}\NormalTok{,}\AttributeTok{details=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

                                    Stepwise Summary                                    
--------------------------------------------------------------------------------------
Step    Variable            AIC         SBC            SBIC           R2       Adj. R2 
--------------------------------------------------------------------------------------
 0      Base Model        1293.366    1303.006     -28281799.310    0.00000    0.00000 
 1      sex_M (+)          988.183    1002.643     -55309468.385    0.28491    0.28413 
 2      deck_F (+)         754.487     773.767     -92534510.256    0.44715    0.44594 
 3      age (+)            721.049     745.149     -99967131.537    0.46813    0.46638 
 4      deck_E (+)         694.782     723.702    -106319323.666    0.48429    0.48203 
 5      pclass_2 (+)       672.910     706.651    -111995587.797    0.49756    0.49480 
 6      sibsp (+)          667.029     705.589    -113925553.460    0.50186    0.49857 
 7      deck_D (+)         661.184     704.564    -115879574.839    0.50611    0.50230 
 8      embarked_Q (+)     659.681     707.881    -116754564.164    0.50799    0.50365 
 9      embarked_Q (-)     661.184     704.564    -115879574.839    0.50611    0.50230 
 10     embarked_C (+)     660.026     708.226    -116666703.385    0.50781    0.50347 
 11     embarked_C (-)     661.184     704.564    -115879574.839    0.50611    0.50230 
--------------------------------------------------------------------------------------

Final Model Output 
------------------

                         Model Summary                          
---------------------------------------------------------------
R                       0.711       RMSE                 0.344 
R-Squared               0.506       MSE                  0.118 
Adj. R-Squared          0.502       Coef. Var           87.122 
Pred R-Squared          0.497       AIC                661.184 
MAE                     0.260       SBC                704.564 
---------------------------------------------------------------
 RMSE: Root Mean Square Error 
 MSE: Mean Square Error 
 MAE: Mean Absolute Error 
 AIC: Akaike Information Criteria 
 SBC: Schwarz Bayesian Criteria 

                                ANOVA                                 
---------------------------------------------------------------------
               Sum of                                                
              Squares         DF    Mean Square       F         Sig. 
---------------------------------------------------------------------
Regression    110.912          7         15.845    132.923    0.0000 
Residual      108.235        908          0.119                      
Total         219.147        915                                     
---------------------------------------------------------------------

                                   Parameter Estimates                                    
-----------------------------------------------------------------------------------------
      model      Beta    Std. Error    Std. Beta       t        Sig      lower     upper 
-----------------------------------------------------------------------------------------
(Intercept)     1.141         0.043                  26.357    0.000     1.056     1.226 
      sex_M    -0.468         0.024       -0.460    -19.226    0.000    -0.516    -0.420 
     deck_F    -0.452         0.031       -0.451    -14.567    0.000    -0.512    -0.391 
        age    -0.007         0.001       -0.176     -7.114    0.000    -0.008    -0.005 
     deck_E     0.163         0.042        0.106      3.852    0.000     0.080     0.247 
   pclass_2     0.142         0.028        0.120      5.024    0.000     0.086     0.197 
      sibsp    -0.031         0.011       -0.067     -2.811    0.005    -0.052    -0.009 
     deck_D    -0.137         0.049       -0.074     -2.795    0.005    -0.233    -0.041 
-----------------------------------------------------------------------------------------
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Fit model with stepwise parms only:}
\NormalTok{binary.model.stepwise }\OtherTok{=} \FunctionTok{glm}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ sex\_M }\SpecialCharTok{+}\NormalTok{ deck\_F  }\SpecialCharTok{+}\NormalTok{ age }\SpecialCharTok{+}\NormalTok{ deck\_E  }\SpecialCharTok{+} 
\NormalTok{                              pclass\_2 }\SpecialCharTok{+}\NormalTok{ pclass\_1 }\SpecialCharTok{+}\NormalTok{ sibsp }\SpecialCharTok{+}\NormalTok{ fare, }
                            \AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train)}
\FunctionTok{summary}\NormalTok{(binary.model.stepwise)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = survived ~ sex_M + deck_F + age + deck_E + pclass_2 + 
    pclass_1 + sibsp + fare, family = binomial, data = train)

Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept)  3.981403   0.438152   9.087  < 2e-16 ***
sex_M       -3.233885   0.242916 -13.313  < 2e-16 ***
deck_F      -2.538492   0.338044  -7.509 5.94e-14 ***
age         -0.056278   0.008733  -6.444 1.16e-10 ***
deck_E       1.832691   0.372320   4.922 8.55e-07 ***
pclass_2     1.353178   0.268462   5.040 4.64e-07 ***
pclass_1     0.625092   0.382656   1.634  0.10235    
sibsp       -0.304005   0.112469  -2.703  0.00687 ** 
fare         0.002005   0.002091   0.959  0.33768    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1230.15  on 915  degrees of freedom
Residual deviance:  654.47  on 907  degrees of freedom
AIC: 672.47

Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Removing fare from stepwise model since its insig.:}
\NormalTok{binary.model.stepwise }\OtherTok{=} \FunctionTok{update}\NormalTok{(binary.model.stepwise, }\FunctionTok{paste}\NormalTok{(}\StringTok{". \textasciitilde{} . {-}"}\NormalTok{, }\StringTok{\textquotesingle{}fare\textquotesingle{}}\NormalTok{))}
\FunctionTok{summary}\NormalTok{(binary.model.stepwise)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = survived ~ sex_M + deck_F + age + deck_E + pclass_2 + 
    pclass_1 + sibsp, family = binomial, data = train)

Coefficients:
             Estimate Std. Error z value Pr(>|z|)    
(Intercept)  4.027774   0.436268   9.232  < 2e-16 ***
sex_M       -3.256877   0.241984 -13.459  < 2e-16 ***
deck_F      -2.559277   0.338208  -7.567 3.81e-14 ***
age         -0.056387   0.008721  -6.465 1.01e-10 ***
deck_E       1.813422   0.372128   4.873 1.10e-06 ***
pclass_2     1.379349   0.267722   5.152 2.58e-07 ***
pclass_1     0.757176   0.357985   2.115  0.03442 *  
sibsp       -0.285271   0.110246  -2.588  0.00967 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1230.15  on 915  degrees of freedom
Residual deviance:  655.42  on 908  degrees of freedom
AIC: 671.42

Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                Model with influential points removed                         \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\# Applying function to remove influential points via Cooks Distance:}
\NormalTok{filtering.result }\OtherTok{=} \FunctionTok{remove\_cooks\_outliers}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train)}
\FunctionTok{cat}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(filtering.result}\SpecialCharTok{$}\NormalTok{high\_cd\_data),}\StringTok{\textquotesingle{}rows were identified as outliers\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0 rows were identified as outliers
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# plot(logmod)}

\CommentTok{\# Since there were now rows identified as outliers, then this model will be the }
\CommentTok{\# same as the initial binary model and need no be considered in the final }
\CommentTok{\# model compare.}

\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                Model with high VIF preds removed                             \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\FunctionTok{library}\NormalTok{(car)}
\FunctionTok{vif}\NormalTok{(lmod)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       age      sibsp      parch       fare   pclass_1   pclass_2      sex_M 
  1.525578   1.241394   1.293316   1.718545   4.501868   1.540346   1.608259 
embarked_C embarked_Q     deck_A     deck_B     deck_C     deck_D     deck_E 
  1.484871   1.397384   5.486232   5.989183   9.392249   8.038956   8.173562 
    deck_F 
 18.354762 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vif.model }\OtherTok{=} \FunctionTok{glm}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ . }\SpecialCharTok{{-}}\NormalTok{deck\_F, }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train)}
\FunctionTok{vif}\NormalTok{(vif.model)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       age      sibsp      parch       fare   pclass_1   pclass_2      sex_M 
  1.514301   1.230447   1.283727   1.719904   4.547578   1.460059   1.463199 
embarked_C embarked_Q     deck_A     deck_B     deck_C     deck_D     deck_E 
  1.478255   1.349790   2.030492   2.311424   2.853072   1.742811   1.584700 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Removing deck\_F from the model eliminates the multicollinearity completely. }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                         Function to calc. cutoff                             \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\NormalTok{cutoff.prg}\OtherTok{\textless{}{-}}\ControlFlowTok{function}\NormalTok{(pred,act)\{}
\CommentTok{\# pred\textless{}{-}predicted\_probabilities}
\CommentTok{\# act\textless{}{-}true\_labels}
\NormalTok{p}\OtherTok{\textless{}{-}}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\FloatTok{0.01}\NormalTok{)}
\NormalTok{n}\OtherTok{\textless{}{-}}\FunctionTok{length}\NormalTok{(p)}
\NormalTok{out}\OtherTok{\textless{}{-}}\FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,}\AttributeTok{nrow=}\NormalTok{n,}\AttributeTok{ncol=}\DecValTok{12}\NormalTok{)}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n)\{}
\NormalTok{predictions }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(pred }\SpecialCharTok{\textgreater{}}\NormalTok{p[i], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{confusion\_matrix }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions),}\FunctionTok{as.factor}\NormalTok{(act),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{out[i,]}\OtherTok{\textless{}{-}}\FunctionTok{cbind}\NormalTok{(}\AttributeTok{p=}\NormalTok{p[i],}\FunctionTok{t}\NormalTok{(confusion\_matrix[[}\DecValTok{4}\NormalTok{]]))}
\NormalTok{\}}
\FunctionTok{dimnames}\NormalTok{(out)[[}\DecValTok{2}\NormalTok{]]}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\StringTok{"p"}\NormalTok{,}\StringTok{"Sensitivity"}\NormalTok{,}\StringTok{"Specificity"}\NormalTok{,}\StringTok{"Pos Pred Value"}\NormalTok{,}\StringTok{"Neg Pred Value"}\NormalTok{,}\StringTok{"Precision"}\NormalTok{,}\StringTok{"Recall"}\NormalTok{, }\StringTok{"F1"}\NormalTok{,}\StringTok{"Prevalence"}\NormalTok{,}\StringTok{"Detection Rate"}\NormalTok{,}\StringTok{"Detection Prevalence"}\NormalTok{, }\StringTok{"Balanced Accuracy"}\NormalTok{)}
\NormalTok{out}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Finding the optimal cutoff}
\NormalTok{observations }\OtherTok{=}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{prob }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lmod, train, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\NormalTok{test\_cutoff}\OtherTok{\textless{}{-}}\FunctionTok{cutoff.prg}\NormalTok{(prob,observations)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(test\_cutoff[,}\DecValTok{1}\NormalTok{],test\_cutoff[,}\DecValTok{8}\NormalTok{],}\AttributeTok{xlab=}\StringTok{"cut off"}\NormalTok{,}\AttributeTok{ylab=}\StringTok{"F1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{FinalProject_files/figure-pdf/unnamed-chunk-26-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{optimal.cutoff }\OtherTok{=}\NormalTok{ test\_cutoff[}\FunctionTok{which.max}\NormalTok{(test\_cutoff[,}\DecValTok{8}\NormalTok{]),]}
\NormalTok{optimal.cutoff[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   p 
0.48 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{observations.train }\OtherTok{=}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{observations.test }\OtherTok{=}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{survived}

\CommentTok{\# Confusion matrix on base log model on train data}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(lmod, train, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions.binary.model.train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{confusion.matrix.binary.model.train }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.train),}\FunctionTok{as.factor}\NormalTok{(observations.train),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{base.model.accuracy }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.train}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{base.model.f1 }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.train}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{base.model.train.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ base.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ base.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(base.model.train.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}base.model.train\textquotesingle{}}

\CommentTok{\# Confusion matrix on base log model on test data}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(lmod, test, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\NormalTok{predictions.binary.model.test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{confusion.matrix.binary.model.test }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.test),}\FunctionTok{as.factor}\NormalTok{(observations.test), }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}

\NormalTok{base.model.accuracy.test }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.test}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{base.model.f1.test }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.test}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}

\NormalTok{base.model.test.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ base.model.accuracy.test,}
  \AttributeTok{F1 =}\NormalTok{ base.model.f1.test}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(base.model.test.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}base.model.test\textquotesingle{}}

\CommentTok{\# Confusion matrix on stepwise log model on train data}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(binary.model.stepwise, train, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions.binary.model.step.train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{confusion.matrix.binary.model.step.train }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.step.train),}\FunctionTok{as.factor}\NormalTok{(observations.train),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{stepwise.model.accuracy }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.step.train}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{stepwise.model.f1 }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.step.train}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{stepwise.model.train.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ stepwise.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ stepwise.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(stepwise.model.train.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}stepwise.model.train\textquotesingle{}}

\CommentTok{\# Confusion matrix on stepwise log model on test data}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(binary.model.stepwise, test, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions.binary.model.step.test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{confusion.matrix.binary.model.step.test }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.step.test),}\FunctionTok{as.factor}\NormalTok{(observations.test),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{stepwise.model.accuracy }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.step.test}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{stepwise.model.f1 }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.step.test}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{stepwise.model.test.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ stepwise.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ stepwise.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(stepwise.model.test.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}stepwise.model.test\textquotesingle{}}

\CommentTok{\# Confusion matrix on log model w/ insig. pred. removed}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(binary.model.filtered, train, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions.binary.model.filtered.train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{confusion.matrix.binary.model.filtered.train }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.filtered.train),}\FunctionTok{as.factor}\NormalTok{(observations.train),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{filtered.model.accuracy }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.filtered.train}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{filtered.model.f1 }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.filtered.train}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{filtered.model.train.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ filtered.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ filtered.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(filtered.model.train.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}filtered.model.train\textquotesingle{}}

\CommentTok{\# Confusion matrix on log model w/ insig. pred. removed}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(binary.model.filtered, test, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}

\NormalTok{predictions.binary.model.filtered.test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{confusion.matrix.binary.model.filtered.test }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.filtered.test),}\FunctionTok{as.factor}\NormalTok{(observations.test),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}

\NormalTok{filtered.model.accuracy }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.filtered.test}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{filtered.model.f1 }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.filtered.test}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}

\NormalTok{filtered.model.test.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ filtered.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ filtered.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(filtered.model.test.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}filtered.model.test\textquotesingle{}}

\CommentTok{\# Confusion matrix on log model w/ high vif pred. removed}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(vif.model, train, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions.binary.model.vif.train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{confusion.matrix.binary.model.vif.train }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.vif.train),}\FunctionTok{as.factor}\NormalTok{(observations.train),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{vif.model.accuracy }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.vif.train}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{vif.model.f1 }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.vif.train}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{vif.model.train.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ vif.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ vif.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(vif.model.train.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}vif.model.train\textquotesingle{}}

\CommentTok{\# Confusion matrix on log model w/ high vif pred. removed}
\NormalTok{y\_hat\_prob }\OtherTok{=} \FunctionTok{predict}\NormalTok{(vif.model, test, }\AttributeTok{type=}\StringTok{"response"}\NormalTok{)}
\NormalTok{predictions.binary.model.vif.test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_prob }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{confusion.matrix.binary.model.vif.test }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.binary.model.vif.test),}\FunctionTok{as.factor}\NormalTok{(observations.test),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{vif.model.accuracy }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.vif.test}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{vif.model.f1 }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.vif.test}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}
\NormalTok{vif.model.test.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ vif.model.accuracy,}
  \AttributeTok{F1 =}\NormalTok{ vif.model.f1}
\NormalTok{)}
\FunctionTok{row.names}\NormalTok{(vif.model.test.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}vif.model.test\textquotesingle{}}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(base.model.train.summary, base.model.test.summary, }
\NormalTok{                 stepwise.model.train.summary, stepwise.model.test.summary,}
\NormalTok{                 filtered.model.train.summary, filtered.model.test.summary,}
\NormalTok{                 vif.model.train.summary,vif.model.test.summary))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrr@{}}
\caption{Comparison of all log models performance}\tabularnewline
\toprule\noalign{}
& Accuracy & F1 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& Accuracy & F1 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
base.model.train & 0.8482533 & 0.8103683 \\
base.model.test & 0.8418367 & 0.7816901 \\
stepwise.model.train & 0.8165939 & 0.7711172 \\
stepwise.model.test & 0.8341837 & 0.7686833 \\
filtered.model.train & 0.8460699 & 0.8081633 \\
filtered.model.test & 0.8418367 & 0.7816901 \\
vif.model.train & 0.8329694 & 0.7906977 \\
vif.model.test & 0.8367347 & 0.7762238 \\
\end{longtable}

\section{Challenger Models}\label{challenger-models}

Build an alternative model based on one of the following approaches to
predict survival as applicable:logistic regression, decision tree, NN,
or SVM, Poisson regression or negative binomial. Check the applicable
model assumptions. Apply in-sample and out-of-sample testing, back
testing and review the comparative goodness of fit of the candidate
models. Describe step by step your procedure to get to the best model
and why you believe it is fit for purpose.

We decided to build a Poisson model for our challenger model. After
building our original poisson model, we first check to see if the
variables are important.

\par

Ho: Variables are not important

\par

Ha: Variable are important

Since we have a p-value of 0, we reject the null hypothesis. Variables
are important.

Our poisson model has three significant variables, pclass\_2, sex\_M,
and deck\_F with an alpha of 0.05.

According to the poisson regression:

\par

The odds of survival increases by 38.16\% when the passenger is second
class. ((exp(0.32326) - 1) * 100)

\par

The odds of survival decreases by 68.37\% when the passenger is male.
((exp(-1.15125) - 1) * 100)

\par

The odds of survival decreases by 63.19\% when the passenger is from
deck G. ((exp(-0.99963) - 1) * 100)

\par

Our Poisson Regression has an accuracy of 75.51\% with optimal
cutoﬀ(.17) based on max F1 score (0.7272).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(MASS)}

\CommentTok{\# Train base Poisson model:}
\NormalTok{poissonReg\_full }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ .,}\AttributeTok{family=}\NormalTok{poisson, train)}

\CommentTok{\# compare the fitted model to the null model and calculate if the variables are important}
\FunctionTok{summary}\NormalTok{(poissonReg\_full)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = survived ~ ., family = poisson, data = train)

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  7.653e-01  3.444e-01   2.222 0.026264 *  
age         -1.776e-02  4.415e-03  -4.023 5.75e-05 ***
sibsp       -5.461e-02  6.961e-02  -0.784 0.432754    
parch        2.236e-02  6.726e-02   0.332 0.739527    
fare         1.401e-06  1.034e-03   0.001 0.998919    
pclass_1     3.840e-01  2.002e-01   1.919 0.055024 .  
pclass_2     5.574e-01  1.533e-01   3.637 0.000276 ***
sex_M       -1.096e+00  1.192e-01  -9.196  < 2e-16 ***
embarked_C   1.461e-01  1.388e-01   1.053 0.292401    
embarked_Q   5.358e-01  2.189e-01   2.447 0.014392 *  
deck_A      -5.240e-01  4.595e-01  -1.140 0.254158    
deck_B      -6.356e-01  4.121e-01  -1.542 0.123013    
deck_C      -6.960e-01  3.946e-01  -1.764 0.077789 .  
deck_D      -7.640e-01  3.886e-01  -1.966 0.049310 *  
deck_E      -1.605e-01  3.569e-01  -0.450 0.652902    
deck_F      -1.554e+00  3.424e-01  -4.537 5.71e-06 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for poisson family taken to be 1)

    Null deviance: 672.00  on 915  degrees of freedom
Residual deviance: 397.76  on 900  degrees of freedom
AIC: 1155.8

Number of Fisher Scoring iterations: 5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pchisq}\NormalTok{(}\FloatTok{672.00{-}409.95}\NormalTok{, }\FunctionTok{length}\NormalTok{(}\FunctionTok{coef}\NormalTok{(poissonReg\_full)) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We then reduce the model and see if the removed variables are significant}
\NormalTok{poissonReg\_reduced }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ pclass\_2}\SpecialCharTok{+}\NormalTok{sex\_M}\SpecialCharTok{+}\NormalTok{deck\_F,}\AttributeTok{family=}\NormalTok{poisson, train)}

\CommentTok{\# Verify that all variables are significant and no more can be dropped}
\FunctionTok{anova}\NormalTok{(poissonReg\_reduced, poissonReg\_full, }\AttributeTok{test=}\StringTok{"Chi"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}rrrrr@{}}
\toprule\noalign{}
Resid. Df & Resid. Dev & Df & Deviance & Pr(\textgreater Chi) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
912 & 428.7449 & NA & NA & NA \\
900 & 397.7597 & 12 & 30.98517 & 0.0019803 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{drop1}\NormalTok{(poissonReg\_reduced,}\AttributeTok{test=}\StringTok{"Chi"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrrr@{}}
\toprule\noalign{}
& Df & Deviance & AIC & LRT & Pr(\textgreater Chi) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& NA & 428.7449 & 1162.745 & NA & NA \\
pclass\_2 & 1 & 435.2529 & 1167.253 & 6.508028 & 0.0107389 \\
sex\_M & 1 & 538.8175 & 1270.818 & 110.072623 & 0.0000000 \\
deck\_F & 1 & 520.5287 & 1252.529 & 91.783810 & 0.0000000 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\# Train Data}

\CommentTok{\# Testing against train data}
\NormalTok{predicted\_probs }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(poissonReg\_reduced, }\AttributeTok{newdata =}\NormalTok{ train, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\CommentTok{\# Get the results of different cutoff values}
\NormalTok{trainResult}\OtherTok{\textless{}{-}}\FunctionTok{cutoff.prg}\NormalTok{(predicted\_probs,train}\SpecialCharTok{$}\NormalTok{survived)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
Warning in confusionMatrix.default(as.factor(predictions), as.factor(act), :
Levels are not in the same order for reference and data. Refactoring data to
match.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We get get the optimal p cut off value based on the maximum F1 score}
\FunctionTok{plot}\NormalTok{(trainResult[,}\DecValTok{1}\NormalTok{],trainResult[,}\DecValTok{8}\NormalTok{],}\AttributeTok{xlab=}\StringTok{"cut off"}\NormalTok{,}\AttributeTok{ylab=}\StringTok{"F1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{FinalProject_files/figure-pdf/poisson-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{poisson.model.cutoff }\OtherTok{=}\NormalTok{ trainResult[}\FunctionTok{which.max}\NormalTok{(trainResult[,}\DecValTok{8}\NormalTok{]),]}

\CommentTok{\# Get the F1 and Accuracy for train data using the optimal p value}
\NormalTok{observations.train }\OtherTok{\textless{}{-}}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{predictions.poisson.model.train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(predicted\_probs }\SpecialCharTok{\textgreater{}}\NormalTok{ poisson.model.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{confusion.matrix.binary.model.poisson.train }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.poisson.model.train),}\FunctionTok{as.factor}\NormalTok{(observations.train), }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}

\NormalTok{poisson.model.accuracy.train }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.poisson.train}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{poisson.model.f1.train }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.poisson.train}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}

\NormalTok{poisson.model.train.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ poisson.model.accuracy.train,}
  \AttributeTok{F1 =}\NormalTok{ poisson.model.f1.train}
\NormalTok{)}

\FunctionTok{row.names}\NormalTok{(poisson.model.train.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}poisson.model.train\textquotesingle{}}

\DocumentationTok{\#\#\# Test Data}

\CommentTok{\# Testing against test data}
\NormalTok{predicted\_probs }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(poissonReg\_reduced, }\AttributeTok{newdata =}\NormalTok{ test, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}

\CommentTok{\# Get the F1 and Accuracy for test data using the optimal p value}
\NormalTok{observations.test }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{predictions.poisson.model.test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(predicted\_probs }\SpecialCharTok{\textgreater{}}\NormalTok{ poisson.model.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\NormalTok{confusion.matrix.binary.model.poisson.test }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions.poisson.model.test),}\FunctionTok{as.factor}\NormalTok{(observations.test), }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}

\NormalTok{poisson.model.accuracy.test }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.poisson.test}\SpecialCharTok{$}\NormalTok{overall[}\StringTok{\textquotesingle{}Accuracy\textquotesingle{}}\NormalTok{]}
\NormalTok{poisson.model.f1.test }\OtherTok{=}\NormalTok{ confusion.matrix.binary.model.poisson.test}\SpecialCharTok{$}\NormalTok{byClass[}\StringTok{\textquotesingle{}F1\textquotesingle{}}\NormalTok{]}

\NormalTok{poisson.model.test.summary }\OtherTok{=} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Accuracy =}\NormalTok{ poisson.model.accuracy.test,}
  \AttributeTok{F1 =}\NormalTok{ poisson.model.f1.test}
\NormalTok{)}

\FunctionTok{row.names}\NormalTok{(poisson.model.test.summary) }\OtherTok{\textless{}{-}} \StringTok{\textquotesingle{}poisson.model.test\textquotesingle{}}

\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(poisson.model.train.summary,poisson.model.test.summary ))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrr@{}}
\toprule\noalign{}
& Accuracy & F1 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
poisson.model.train & 0.7652838 & 0.7592385 \\
poisson.model.test & 0.7551020 & 0.7257143 \\
\end{longtable}

\section{Model Limitation and
Assumptions}\label{model-limitation-and-assumptions}

The champion model selected is the filtered logistic regression model
due to its superior train accuracy (85.04\%) and F1 score (0.8099). The
filtered logistic regression model was developed through backward
elimination procedure, applied to the full base model. This process
iteratively removed predictors with high p-values until only
statistically significant predictors remained, based on threshold (p
\textless0.05). The base model is used as the benchmark due to its
similar performance and broader feature set.

``Survived = 5.56 - 0.055age - 0.23sibsp + 1pclass\_1 + 1.9pclass\_2 -
3.2sex\_M + 0.84embarked\_C + 0.86embarked\_Q - 2.5deck\_A - 1.9deck\_B
- 2.1deck\_C - 3.1deck\_D - 4.6deck\_F''

To further evaluate and benchmark the logistic regression models, we
computed RMSE, R², and MAE using the predicted probabilities against the
actual binary outcomes. While traditional R² is not appropriate for
logistic models, these metrics provide insight into how well the
predicted probabilities align with observed outcomes. The Filtered model
appears to have higher R² (0.4425\textgreater0.4342), lower RMSE(0.3945
\textless{} 0.3977) and MAE (0.1556 \textless0.1582). Additionally,
model validation was done through train/test split with consistent
performance across sets. The performance on test data and train data
show minimal difference, indicating the model is robust, no overfitting
problem.

To evaluate the stability and fit of the base and filtered logistic
regression models, we conducted residual-based tests on their linear
analogs. While logistic regression does not formally require normally
distributed or homoscedastic residuals, these tests offer insights into
model specification quality and residual behavior.

Breusch-Pagan Test: Both models exhibit statistically significant
heteroskedasticity (p \textless{} 0.01)

Shapiro-Wilk Test: Both models show highly significant deviations from
normality (p \textless{} 0.01)

Both models show similar residual behavior, with slight
heteroskedasticity and non-normality. These findings do not violate
logistic regression assumptions but suggest the model could be further
improved through additional transformations or interaction terms.

Multicollinearity was significantly lower in the filtered model (max
VIF: 3.69 vs.~16.63), supporting better generalization and
interpretability. The VIF is less than 5, confirmed no severe
multicollinearity.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(car)}

\CommentTok{\# Normality Test}
\CommentTok{\# Breusch Pagan Test on Logistic Model}
\NormalTok{BPtest\_basemodel }\OtherTok{\textless{}{-}} \FunctionTok{ols\_test\_breusch\_pagan}\NormalTok{(lmod)}
\NormalTok{BPtest\_filtered.model }\OtherTok{\textless{}{-}} \FunctionTok{ols\_test\_breusch\_pagan}\NormalTok{(binary.model.filtered)}

\CommentTok{\# Shapiro{-}Wilk test}
\NormalTok{SWtest\_basemodel }\OtherTok{\textless{}{-}} \FunctionTok{shapiro.test}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(lmod))}
\NormalTok{SWtest\_filteredmodel }\OtherTok{\textless{}{-}} \FunctionTok{shapiro.test}\NormalTok{(}\FunctionTok{residuals}\NormalTok{(binary.model.filtered))}


\CommentTok{\# Combine into unified rows}
\NormalTok{diagnostics\_summary }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}
  \AttributeTok{Model =} \FunctionTok{c}\NormalTok{(}\StringTok{"Base.model"}\NormalTok{, }\StringTok{"Filtered.model"}\NormalTok{),}
  \AttributeTok{BP\_Statistic =} \FunctionTok{c}\NormalTok{(BPtest\_basemodel}\SpecialCharTok{$}\NormalTok{bp, BPtest\_filtered.model}\SpecialCharTok{$}\NormalTok{bp),}
  \AttributeTok{BP\_pvalue =} \FunctionTok{c}\NormalTok{(BPtest\_basemodel}\SpecialCharTok{$}\NormalTok{p, BPtest\_filtered.model}\SpecialCharTok{$}\NormalTok{p),}
  \AttributeTok{Shapiro\_W =} \FunctionTok{c}\NormalTok{(SWtest\_basemodel}\SpecialCharTok{$}\NormalTok{statistic, SWtest\_filteredmodel}\SpecialCharTok{$}\NormalTok{statistic),}
  \AttributeTok{Shapiro\_pvalue =} \FunctionTok{c}\NormalTok{(SWtest\_basemodel}\SpecialCharTok{$}\NormalTok{p.value, SWtest\_filteredmodel}\SpecialCharTok{$}\NormalTok{p.value)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diagnostics\_summary}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrrr@{}}
\caption{Summary of Diagnostic tests on Filtered vs Base
models}\tabularnewline
\toprule\noalign{}
Model & BP\_Statistic & BP\_pvalue & Shapiro\_W & Shapiro\_pvalue \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Model & BP\_Statistic & BP\_pvalue & Shapiro\_W & Shapiro\_pvalue \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Base.model & 8.818434 & 0.0029820 & 0.9741629 & 0 \\
Filtered.model & 8.766123 & 0.0030688 & 0.9740530 & 0 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Run VIF on the logistic model}
\FunctionTok{ols\_vif\_tol}\NormalTok{(lmod)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrr@{}}
\caption{VIF Results for Base Logistic Regression Model}\tabularnewline
\toprule\noalign{}
Variables & Tolerance & VIF \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Variables & Tolerance & VIF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
age & 0.8014421 & 1.247751 \\
sibsp & 0.8139299 & 1.228607 \\
parch & 0.7767675 & 1.287386 \\
fare & 0.5106963 & 1.958111 \\
pclass\_1 & 0.2390773 & 4.182747 \\
pclass\_2 & 0.7882882 & 1.268572 \\
sex\_M & 0.8536797 & 1.171399 \\
embarked\_C & 0.7283295 & 1.373005 \\
embarked\_Q & 0.8516863 & 1.174141 \\
deck\_A & 0.2417476 & 4.136545 \\
deck\_B & 0.1524257 & 6.560574 \\
deck\_C & 0.1073871 & 9.312101 \\
deck\_D & 0.1437156 & 6.958186 \\
deck\_E & 0.1096865 & 9.116889 \\
deck\_F & 0.0518910 & 19.271182 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ols\_vif\_tol}\NormalTok{(binary.model.filtered)}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrr@{}}
\caption{VIF Results for Filtered Logistic Regression
Model}\tabularnewline
\toprule\noalign{}
Variables & Tolerance & VIF \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
Variables & Tolerance & VIF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
age & 0.8235167 & 1.214304 \\
sibsp & 0.9311335 & 1.073960 \\
pclass\_1 & 0.2691220 & 3.715787 \\
pclass\_2 & 0.7993736 & 1.250980 \\
sex\_M & 0.9116354 & 1.096930 \\
embarked\_C & 0.7494085 & 1.334386 \\
embarked\_Q & 0.8625361 & 1.159372 \\
deck\_A & 0.6445365 & 1.551503 \\
deck\_B & 0.4997149 & 2.001141 \\
deck\_C & 0.4310400 & 2.319970 \\
deck\_D & 0.5876091 & 1.701812 \\
deck\_F & 0.3665167 & 2.728389 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Base Model {-} Train}
\NormalTok{observations.train }\OtherTok{\textless{}{-}}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{y\_hat\_base\_train }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lmod, train, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{pred\_base\_train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_base\_train }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTrain\_base }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ observations.train, }\AttributeTok{pred =}\NormalTok{ pred\_base\_train)}
\NormalTok{log.train.base }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTrain\_base)}

\CommentTok{\# Base Model {-} Test}
\NormalTok{observations.test }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{y\_hat\_base\_test }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(lmod, test, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{pred\_base\_test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_base\_test }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTest\_base }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ observations.test, }\AttributeTok{pred =}\NormalTok{ pred\_base\_test)}
\NormalTok{log.test.base }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTest\_base)}

\CommentTok{\# Base Model {-} Train}
\NormalTok{observations.train }\OtherTok{\textless{}{-}}\NormalTok{ train}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{y\_hat\_base\_train }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(binary.model.filtered, train, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{pred\_base\_train }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_base\_train }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTrain\_base }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ observations.train, }\AttributeTok{pred =}\NormalTok{ pred\_base\_train)}
\NormalTok{filtered.log.train.base }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTrain\_base)}

\CommentTok{\# Base Model {-} Test}
\NormalTok{observations.test }\OtherTok{\textless{}{-}}\NormalTok{ test}\SpecialCharTok{$}\NormalTok{survived}
\NormalTok{y\_hat\_base\_test }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(binary.model.filtered, test, }\AttributeTok{type =} \StringTok{"response"}\NormalTok{)}
\NormalTok{pred\_base\_test }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_base\_test }\SpecialCharTok{\textgreater{}}\NormalTok{ optimal.cutoff[}\DecValTok{1}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTest\_base }\OtherTok{\textless{}{-}} \FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ observations.test, }\AttributeTok{pred =}\NormalTok{ pred\_base\_test)}
\NormalTok{filtered.test.base }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTest\_base)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(log.train.base,log.test.base,filtered.log.train.base,filtered.test.base))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrr@{}}
\caption{Comparison of stats between base and filtered log
models:}\tabularnewline
\toprule\noalign{}
& RMSE & Rsquared & MAE \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& RMSE & Rsquared & MAE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
log.train.base & 0.3895468 & 0.4678500 & 0.1517467 \\
log.test.base & 0.3976975 & 0.4341949 & 0.1581633 \\
filtered.log.train.base & 0.3923393 & 0.4621351 & 0.1539301 \\
filtered.test.base & 0.3976975 & 0.4341949 & 0.1581633 \\
\end{longtable}

\section{Ongoing Model Monitoring
Plan}\label{ongoing-model-monitoring-plan}

In order to maintain the effectiveness of the model, we would need to
continue to test it on new data. Since the Titanic was a rare event, we
do not have a lot of new data to test on the model, but we can still be
prepared in case new data were to become available. The first step in
monitoring the model is to determine specific thresholds that we expect
the model to stay above. We would want the model to maintain certain
R\^{}2, RMSE, and MAE values in order to determine that the model is
working correctly. One of the biggest concerns with our model is data
drift. Since the Titanic sank over 100 years ago, the data that we are
using from the model may not align with today relevant to ship travel
today.

\section{Conclusion}\label{conclusion}

As we can see from the comparing all three models. The ``vif.model''
performed the base against the test data set. This is due to the removal
high vif variables until our model reached a total VIF under 10 for each
variable. Multicollinarity was a big factor that impacted our models
accuracy and F1. Once we removed indications multicollinarity, we could
see that our models performance increased over the base model.

However, with the ``poisson.model'', we see a decrease in accuracy
compared the base model. This decrease is expected due to the nature of
the poisson regression. The regression is most useful when the response
variable is a count variable rather than a binary response. Thus a
decrease in accuracy and F1 is expected against the base model.

As a conclusion, the model reduced via VIF is the best model to predict
if a passenger were to survive, with an accuracy of 85.20\% and improved
over the base model by 0.25\%.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(base.model.test.summary, }
\NormalTok{                 vif.model.test.summary,}
\NormalTok{                 poisson.model.test.summary))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrr@{}}
\caption{Comparison of our base model, best performing developed model,
and challenger model}\tabularnewline
\toprule\noalign{}
& Accuracy & F1 \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
& Accuracy & F1 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
base.model.test & 0.8418367 & 0.7816901 \\
vif.model.test & 0.8367347 & 0.7762238 \\
poisson.model.test & 0.7551020 & 0.7257143 \\
\end{longtable}

\section*{Appendix A: Check if `sibsp' and `parch' should be continuous
or categorical}\label{appendix_A}
\addcontentsline{toc}{section}{Appendix A: Check if `sibsp' and `parch'
should be continuous or categorical}

We don't see significant improvement between modeling these predictors
as continuous or categorical, therefore we decided to leave them as
continuous.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(car)}
\NormalTok{data.clean.ap1 }\OtherTok{=}\NormalTok{ odata[, }\SpecialCharTok{!}\NormalTok{(}\FunctionTok{names}\NormalTok{(odata) }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"name"}\NormalTok{, }\StringTok{"ticket"}\NormalTok{, }\StringTok{"boat"}\NormalTok{,}\StringTok{"body"}\NormalTok{,}\StringTok{"home.dest"}\NormalTok{))]}

\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                           Data Augmentation                                  \#   }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#Extract deck letter from cabin}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{substr}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{cabin, }\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}

\CommentTok{\# Remove cabin col:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{cabin }\OtherTok{\textless{}{-}} \ConstantTok{NULL}

\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                           Imputing data                                      \#   }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}

\CommentTok{\# {-}{-}{-}{-} Age{-}{-}{-}{-}}
\CommentTok{\#Replace NAs in age column with Median value }
\NormalTok{median\_age }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{age, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{data.clean.ap1 }\OtherTok{\textless{}{-}}\NormalTok{ data.clean.ap1 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{age =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(age), median\_age, age))}

\CommentTok{\# {-}{-}{-}{-} deck{-}{-}{-}{-}}
\CommentTok{\# For deck, since its a category, we decided to use KNN  to impute the column:}

\CommentTok{\# Install if not already installed}
\CommentTok{\# install.packages("VIM")}
\FunctionTok{library}\NormalTok{(VIM)}

\CommentTok{\# Replace "" with NA in the \textquotesingle{}deck\textquotesingle{} column}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck[data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{""}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NA}

\CommentTok{\# Convert \textquotesingle{}cabin\textquotesingle{} to factor}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck)}

\CommentTok{\# Apply kNN imputation just to Cabin column}
\NormalTok{data.clean.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{kNN}\NormalTok{(data.clean.ap1, }\AttributeTok{variable =} \StringTok{"deck"}\NormalTok{, }\AttributeTok{k =} \DecValTok{5}\NormalTok{)}

\CommentTok{\# Check that NAs were imputed}
\CommentTok{\# sum(is.na(data.clean$deck))        \# Original}
\CommentTok{\# sum(is.na(data.clean.imputed$deck)) \# After}

\CommentTok{\# Remove indicator col:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck\_imp }\OtherTok{\textless{}{-}} \ConstantTok{NULL}

\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                           Dummify Cat. cols                                  \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}

\CommentTok{\# Dummifying pclass:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{pclass\_1 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{pclass }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{pclass\_2 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{pclass }\SpecialCharTok{==} \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying sex:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{sex\_M }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{sex }\SpecialCharTok{==} \StringTok{\textquotesingle{}male\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying embarked:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{embarked\_C }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{embarked }\SpecialCharTok{==} \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{embarked\_Q }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{embarked }\SpecialCharTok{==} \StringTok{\textquotesingle{}Q\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying deck:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck\_A }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck\_B }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck\_C }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck\_D }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck\_E }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck\_F }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\CommentTok{\#data.clean.ap1$deck\_G = ifelse(data.clean.ap1$deck == \textquotesingle{}G\textquotesingle{}, 1, 0) \# removed due to causing issues}

\CommentTok{\# Dummifying sibsp:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp\_1 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp\_2 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp }\SpecialCharTok{==} \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp\_3 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp }\SpecialCharTok{==} \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp\_4 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp }\SpecialCharTok{==} \DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp\_5 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{sibsp }\SpecialCharTok{==} \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\CommentTok{\#data.clean.ap1$sibsp\_8 = ifelse(data.clean.ap1$sibsp == 8, 1, 0) \# removed due to causing issues}

\CommentTok{\# Dummifying parch:}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch\_1 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch\_2 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch }\SpecialCharTok{==} \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch\_3 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch }\SpecialCharTok{==} \DecValTok{3}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch\_4 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch }\SpecialCharTok{==} \DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch\_5 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch }\SpecialCharTok{==} \DecValTok{5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch\_6 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap1}\SpecialCharTok{$}\NormalTok{parch }\SpecialCharTok{==} \DecValTok{6}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\CommentTok{\#data.clean.ap1$parch\_9 = ifelse(data.clean.ap1$parch == 9, 1, 0) \# removed due to causing issues}

\CommentTok{\# Removing Dummified cols:}
\NormalTok{data.clean.ap1 }\OtherTok{=} \FunctionTok{subset}\NormalTok{(data.clean.ap1, }\AttributeTok{select  =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(pclass, sex, embarked, deck))}\CommentTok{\#, sibsp, parch))}

\NormalTok{data.clean.ap1 }\OtherTok{=} \FunctionTok{na.omit}\NormalTok{(data.clean.ap1)}

\FunctionTok{cat}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(odata) }\SpecialCharTok{{-}} \FunctionTok{nrow}\NormalTok{(data.clean.ap1),}\StringTok{\textquotesingle{}rows were removed from original dataset\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
2 rows were removed from original dataset
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{567}\NormalTok{)}
\NormalTok{train\_indices\_ap1 }\OtherTok{=} \FunctionTok{sample}\NormalTok{(}\DecValTok{1} \SpecialCharTok{:} \FunctionTok{nrow}\NormalTok{(data.clean.ap1), }\AttributeTok{size =} \FloatTok{0.7005}\SpecialCharTok{*}\FunctionTok{nrow}\NormalTok{(data.clean.ap1), }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{train.ap1 }\OtherTok{=}\NormalTok{ data.clean.ap1[train\_indices\_ap1,]}
\NormalTok{test.ap1 }\OtherTok{=}\NormalTok{ data.clean.ap1[}\SpecialCharTok{{-}}\NormalTok{train\_indices\_ap1,]}
\FunctionTok{cat}\NormalTok{(}\StringTok{"We are using:"}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(train.ap1)}\SpecialCharTok{/}\FunctionTok{nrow}\NormalTok{(data.clean.ap1) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\StringTok{\textquotesingle{}\% of the data for training\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
We are using: 70.03058 % of the data for training
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mulvar\_model.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train.ap1)}
\FunctionTok{summary}\NormalTok{(mulvar\_model.ap1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = survived ~ ., data = train.ap1)

Residuals:
    Min      1Q  Median      3Q     Max 
-1.2866 -0.1941 -0.0224  0.1911  0.9739 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.1796068  0.1203338   9.803  < 2e-16 ***
age         -0.0064249  0.0010420  -6.166 1.06e-09 ***
sibsp       -0.0401162  0.0221954  -1.807  0.07104 .  
parch       -0.0274112  0.0270379  -1.014  0.31095    
fare         0.0004356  0.0002985   1.459  0.14481    
pclass_1     0.1097829  0.0542228   2.025  0.04320 *  
pclass_2     0.1381701  0.0312063   4.428 1.07e-05 ***
sex_M       -0.4129619  0.0252816 -16.335  < 2e-16 ***
embarked_C   0.0461410  0.0323127   1.428  0.15366    
embarked_Q   0.1210184  0.0426024   2.841  0.00461 ** 
deck_A      -0.3494376  0.1454048  -2.403  0.01646 *  
deck_B      -0.3123626  0.1372942  -2.275  0.02314 *  
deck_C      -0.3040370  0.1331009  -2.284  0.02259 *  
deck_D      -0.3432119  0.1290127  -2.660  0.00795 ** 
deck_E       0.0041655  0.1243264   0.034  0.97328    
deck_F      -0.5934388  0.1184958  -5.008 6.63e-07 ***
sibsp_1      0.0567316  0.0355896   1.594  0.11128    
sibsp_2      0.1212082  0.0797596   1.520  0.12895    
sibsp_3     -0.1501858  0.1195550  -1.256  0.20937    
sibsp_4     -0.2298081  0.1296372  -1.773  0.07662 .  
sibsp_5     -0.2293432  0.2019073  -1.136  0.25631    
parch_1      0.1426458  0.0454040   3.142  0.00174 ** 
parch_2      0.1456666  0.0715147   2.037  0.04196 *  
parch_3      0.2704118  0.1739380   1.555  0.12039    
parch_4     -0.0799175  0.2038416  -0.392  0.69511    
parch_5      0.0679073  0.2385574   0.285  0.77597    
parch_6      0.0143690  0.2895211   0.050  0.96043    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.34 on 889 degrees of freedom
Multiple R-squared:  0.5273,    Adjusted R-squared:  0.5135 
F-statistic: 38.14 on 26 and 889 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(mulvar\_model.ap1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       age      sibsp      parch       fare   pclass_1   pclass_2      sex_M 
  1.460949   3.467000   4.494487   1.922834   4.492433   1.297793   1.164100 
embarked_C embarked_Q     deck_A     deck_B     deck_C     deck_D     deck_E 
  1.437150   1.172137   5.135825   8.715727  13.411354   9.672668  12.015361 
    deck_F    sibsp_1    sibsp_2    sibsp_3    sibsp_4    sibsp_5    parch_1 
 26.716246   1.876291   1.441990   1.464254   1.863037   1.404398   1.911901 
   parch_2    parch_3    parch_4    parch_5    parch_6 
  3.083293   1.301393   1.431435   1.472004   1.446997 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lmod.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(survived) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train.ap1)}
\FunctionTok{summary}\NormalTok{(lmod.ap1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = as.factor(survived) ~ ., family = binomial, data = train.ap1)

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  5.253e+00  1.384e+00   3.797 0.000147 ***
age         -5.481e-02  9.965e-03  -5.500 3.79e-08 ***
sibsp       -1.946e+00  1.291e+02  -0.015 0.987976    
parch       -1.642e+00  1.623e+02  -0.010 0.991928    
fare         1.057e-03  2.428e-03   0.435 0.663393    
pclass_1     1.156e+00  4.819e-01   2.398 0.016480 *  
pclass_2     1.496e+00  3.095e-01   4.834 1.34e-06 ***
sex_M       -2.982e+00  2.464e-01 -12.103  < 2e-16 ***
embarked_C   6.410e-01  2.868e-01   2.235 0.025424 *  
embarked_Q   1.316e+00  3.735e-01   3.523 0.000427 ***
deck_A      -2.866e+00  1.503e+00  -1.907 0.056492 .  
deck_B      -2.498e+00  1.479e+00  -1.689 0.091220 .  
deck_C      -2.624e+00  1.445e+00  -1.817 0.069262 .  
deck_D      -2.971e+00  1.415e+00  -2.100 0.035711 *  
deck_E       3.196e-01  1.404e+00   0.228 0.819965    
deck_F      -4.753e+00  1.358e+00  -3.499 0.000467 ***
sibsp_1      2.065e+00  1.291e+02   0.016 0.987240    
sibsp_2      4.356e+00  2.583e+02   0.017 0.986546    
sibsp_3      3.607e+00  3.874e+02   0.009 0.992572    
sibsp_4      4.557e+00  5.166e+02   0.009 0.992962    
sibsp_5     -6.723e+00  1.240e+03  -0.005 0.995674    
parch_1      2.597e+00  1.623e+02   0.016 0.987237    
parch_2      4.192e+00  3.247e+02   0.013 0.989698    
parch_3      6.236e+00  4.870e+02   0.013 0.989785    
parch_4      6.227e+00  6.494e+02   0.010 0.992349    
parch_5      8.544e+00  8.117e+02   0.011 0.991602    
parch_6     -4.112e+00  1.770e+03  -0.002 0.998146    
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1223.12  on 915  degrees of freedom
Residual deviance:  602.86  on 889  degrees of freedom
AIC: 656.86

Number of Fisher Scoring iterations: 15
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(lmod.ap1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         age        sibsp        parch         fare     pclass_1     pclass_2 
1.653195e+00 7.591027e+05 1.634339e+06 1.757536e+00 4.949336e+00 1.555093e+00 
       sex_M   embarked_C   embarked_Q       deck_A       deck_B       deck_C 
1.404155e+00 1.549826e+00 1.415978e+00 1.012962e+01 1.475410e+01 2.517074e+01 
      deck_D       deck_E       deck_F      sibsp_1      sibsp_2      sibsp_3 
1.980371e+01 1.464836e+01 4.346983e+01 3.294475e+05 1.808931e+05 1.937224e+05 
     sibsp_4      sibsp_5      parch_1      parch_2      parch_3      parch_4 
1.974919e+05 1.372219e+00 3.139987e+05 6.986245e+05 2.469813e+05 2.280957e+05 
     parch_5      parch_6 
4.056249e+05 1.434520e+00 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_hat\_mulvar\_train.ap1}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(mulvar\_model.ap1, }\AttributeTok{data =}\NormalTok{ train.ap1)}
\NormalTok{predictions\_train.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_mulvar\_train.ap1 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTrain\_mulvar.ap1}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ train.ap1}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{predictions\_train.ap1)}
\NormalTok{linear.train.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTrain\_mulvar.ap1)}

\NormalTok{y\_hat\_mulvar\_test.ap1}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(mulvar\_model.ap1, }\AttributeTok{newdata =}\NormalTok{ test.ap1)}
\NormalTok{predictions\_test.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_mulvar\_test.ap1 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTest\_mulvar.ap1}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ test.ap1}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{predictions\_test.ap1)}
\NormalTok{linear.test.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTest\_mulvar.ap1)}


\NormalTok{y\_hat\_log\_train.ap1}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(lmod.ap1, }\AttributeTok{data =}\NormalTok{ train.ap1)}
\NormalTok{predictions\_log\_train.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_log\_train.ap1 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTrain\_lmod.ap1}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ train.ap1}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{predictions\_log\_train.ap1)}
\NormalTok{log.train.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTrain\_lmod.ap1)}

\NormalTok{y\_hat\_log\_test.ap1}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(lmod.ap1, }\AttributeTok{newdata =}\NormalTok{ test.ap1)}
\NormalTok{predictions\_log\_test.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_log\_test.ap1 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTest\_lmod.ap1}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ test.ap1}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{predictions\_log\_test.ap1)}
\NormalTok{log.test.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTest\_lmod.ap1)}

\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(linear.train.ap1,linear.test.ap1,log.train.ap1,log.test.ap1))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrr@{}}
\toprule\noalign{}
& RMSE & Rsquared & MAE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
linear.train.ap1 & 0.3796114 & 0.4824536 & 0.1441048 \\
linear.test.ap1 & 0.3976975 & 0.4365256 & 0.1581633 \\
log.train.ap1 & 0.3964912 & 0.4429840 & 0.1572052 \\
log.test.ap1 & 0.4008919 & 0.4214242 & 0.1607143 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_mulvar\_train.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_train.ap1), }\FunctionTok{as.factor}\NormalTok{(train.ap1}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_mulvar\_train.ap1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 502  73
         1  59 282
                                         
               Accuracy : 0.8559         
                 95% CI : (0.8315, 0.878)
    No Information Rate : 0.6124         
    P-Value [Acc > NIR] : <2e-16         
                                         
                  Kappa : 0.6942         
                                         
 Mcnemar's Test P-Value : 0.2578         
                                         
              Precision : 0.8270         
                 Recall : 0.7944         
                     F1 : 0.8103         
             Prevalence : 0.3876         
         Detection Rate : 0.3079         
   Detection Prevalence : 0.3723         
      Balanced Accuracy : 0.8446         
                                         
       'Positive' Class : 1              
                                         
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_mulvar\_test.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_test.ap1), }\FunctionTok{as.factor}\NormalTok{(test.ap1}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_mulvar\_test.ap1  }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 216  31
         1  31 114
                                          
               Accuracy : 0.8418          
                 95% CI : (0.8019, 0.8765)
    No Information Rate : 0.6301          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6607          
                                          
 Mcnemar's Test P-Value : 1               
                                          
              Precision : 0.7862          
                 Recall : 0.7862          
                     F1 : 0.7862          
             Prevalence : 0.3699          
         Detection Rate : 0.2908          
   Detection Prevalence : 0.3699          
      Balanced Accuracy : 0.8304          
                                          
       'Positive' Class : 1               
                                          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_log\_train.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_log\_train.ap1), }\FunctionTok{as.factor}\NormalTok{(train.ap1}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_log\_train.ap1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 523 106
         1  38 249
                                          
               Accuracy : 0.8428          
                 95% CI : (0.8176, 0.8658)
    No Information Rate : 0.6124          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6568          
                                          
 Mcnemar's Test P-Value : 2.36e-08        
                                          
              Precision : 0.8676          
                 Recall : 0.7014          
                     F1 : 0.7757          
             Prevalence : 0.3876          
         Detection Rate : 0.2718          
   Detection Prevalence : 0.3133          
      Balanced Accuracy : 0.8168          
                                          
       'Positive' Class : 1               
                                          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_log\_test.ap1 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_log\_test.ap1), }\FunctionTok{as.factor}\NormalTok{(test.ap1}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_log\_test.ap1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 226  42
         1  21 103
                                          
               Accuracy : 0.8393          
                 95% CI : (0.7991, 0.8742)
    No Information Rate : 0.6301          
    P-Value [Acc > NIR] : < 2e-16         
                                          
                  Kappa : 0.6446          
                                          
 Mcnemar's Test P-Value : 0.01174         
                                          
              Precision : 0.8306          
                 Recall : 0.7103          
                     F1 : 0.7658          
             Prevalence : 0.3699          
         Detection Rate : 0.2628          
   Detection Prevalence : 0.3163          
      Balanced Accuracy : 0.8127          
                                          
       'Positive' Class : 1               
                                          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(car)}
\NormalTok{data.clean.ap2 }\OtherTok{=}\NormalTok{ odata[, }\SpecialCharTok{!}\NormalTok{(}\FunctionTok{names}\NormalTok{(odata) }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"name"}\NormalTok{, }\StringTok{"ticket"}\NormalTok{, }\StringTok{"boat"}\NormalTok{,}\StringTok{"body"}\NormalTok{,}\StringTok{"home.dest"}\NormalTok{))]}

\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                           Data Augmentation                                  \#   }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#Extract deck letter from cabin}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{substr}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{cabin, }\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{)}

\CommentTok{\# Remove cabin col:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{cabin }\OtherTok{\textless{}{-}} \ConstantTok{NULL}

\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                           Imputing data                                      \#   }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}

\CommentTok{\# {-}{-}{-}{-} Age{-}{-}{-}{-}}
\CommentTok{\#Replace NAs in age column with Median value }
\NormalTok{median\_age }\OtherTok{\textless{}{-}} \FunctionTok{median}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{age, }\AttributeTok{na.rm =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{data.clean.ap2 }\OtherTok{\textless{}{-}}\NormalTok{ data.clean.ap2 }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{age =} \FunctionTok{ifelse}\NormalTok{(}\FunctionTok{is.na}\NormalTok{(age), median\_age, age))}

\CommentTok{\# {-}{-}{-}{-} deck{-}{-}{-}{-}}
\CommentTok{\# For deck, since its a category, we decided to use KNN  to impute the column:}

\CommentTok{\# Install if not already installed}
\CommentTok{\# install.packages("VIM")}
\FunctionTok{library}\NormalTok{(VIM)}

\CommentTok{\# Replace "" with NA in the \textquotesingle{}deck\textquotesingle{} column}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck[data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{""}\NormalTok{] }\OtherTok{\textless{}{-}} \ConstantTok{NA}

\CommentTok{\# Convert \textquotesingle{}cabin\textquotesingle{} to factor}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\OtherTok{\textless{}{-}} \FunctionTok{as.factor}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck)}

\CommentTok{\# Apply kNN imputation just to Cabin column}
\NormalTok{data.clean.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{kNN}\NormalTok{(data.clean.ap2, }\AttributeTok{variable =} \StringTok{"deck"}\NormalTok{, }\AttributeTok{k =} \DecValTok{5}\NormalTok{)}

\CommentTok{\# Check that NAs were imputed}
\CommentTok{\# sum(is.na(data.clean$deck))        \# Original}
\CommentTok{\# sum(is.na(data.clean.imputed$deck)) \# After}

\CommentTok{\# Remove indicator col:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck\_imp }\OtherTok{\textless{}{-}} \ConstantTok{NULL}


\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}
\CommentTok{\#                           Dummify Cat. cols                                  \# }
\DocumentationTok{\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#\#}

\CommentTok{\# Dummifying pclass:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{pclass\_1 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{pclass }\SpecialCharTok{==} \DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{pclass\_2 }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{pclass }\SpecialCharTok{==} \DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying sex:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{sex\_M }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{sex }\SpecialCharTok{==} \StringTok{\textquotesingle{}male\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying embarked:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{embarked\_C }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{embarked }\SpecialCharTok{==} \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{embarked\_Q }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{embarked }\SpecialCharTok{==} \StringTok{\textquotesingle{}Q\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying deck:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck\_A }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}A\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck\_B }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}B\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck\_C }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}C\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck\_D }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}D\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck\_E }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}E\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck\_F }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{deck }\SpecialCharTok{==} \StringTok{\textquotesingle{}F\textquotesingle{}}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\CommentTok{\#data.clean.ap2$deck\_G = ifelse(data.clean.ap2$deck == \textquotesingle{}G\textquotesingle{}, 1, 0) \# removed due to causing issues}

\CommentTok{\# Dummifying sibsp to 2 categories:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{sibsp\_y }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{sibsp }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Dummifying parch to 2 categories:}
\NormalTok{data.clean.ap2}\SpecialCharTok{$}\NormalTok{parch\_y }\OtherTok{=} \FunctionTok{ifelse}\NormalTok{(data.clean.ap2}\SpecialCharTok{$}\NormalTok{parch }\SpecialCharTok{\textgreater{}} \DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}

\CommentTok{\# Removing Dummified cols:}
\NormalTok{data.clean.ap2 }\OtherTok{=} \FunctionTok{subset}\NormalTok{(data.clean.ap2, }\AttributeTok{select  =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(pclass, sex, embarked, deck))}\CommentTok{\#, sibsp, parch))}

\NormalTok{data.clean.ap2 }\OtherTok{=} \FunctionTok{na.omit}\NormalTok{(data.clean.ap2)}

\FunctionTok{cat}\NormalTok{(}\FunctionTok{nrow}\NormalTok{(odata) }\SpecialCharTok{{-}} \FunctionTok{nrow}\NormalTok{(data.clean.ap2),}\StringTok{\textquotesingle{}rows were removed from original dataset\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
2 rows were removed from original dataset
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{567}\NormalTok{)}
\NormalTok{train\_indices\_ap2 }\OtherTok{=} \FunctionTok{sample}\NormalTok{(}\DecValTok{1} \SpecialCharTok{:} \FunctionTok{nrow}\NormalTok{(data.clean.ap2), }\AttributeTok{size =} \FloatTok{0.7005}\SpecialCharTok{*}\FunctionTok{nrow}\NormalTok{(data.clean.ap2), }\AttributeTok{replace =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{train.ap2 }\OtherTok{=}\NormalTok{ data.clean.ap2[train\_indices\_ap2,]}
\NormalTok{test.ap2 }\OtherTok{=}\NormalTok{ data.clean.ap2[}\SpecialCharTok{{-}}\NormalTok{train\_indices\_ap2,]}
\FunctionTok{cat}\NormalTok{(}\StringTok{"We are using:"}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(train.ap2)}\SpecialCharTok{/}\FunctionTok{nrow}\NormalTok{(data.clean.ap2) }\SpecialCharTok{*} \DecValTok{100}\NormalTok{, }\StringTok{\textquotesingle{}\% of the data for training\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
We are using: 70.03058 % of the data for training
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mulvar\_model.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{lm}\NormalTok{(survived }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{data =}\NormalTok{ train.ap2)}
\FunctionTok{summary}\NormalTok{(mulvar\_model.ap2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
lm(formula = survived ~ ., data = train.ap2)

Residuals:
     Min       1Q   Median       3Q      Max 
-1.27243 -0.19451 -0.02769  0.19202  0.96436 

Coefficients:
              Estimate Std. Error t value Pr(>|t|)    
(Intercept)  1.1720948  0.1212992   9.663  < 2e-16 ***
age         -0.0061866  0.0010236  -6.044 2.20e-09 ***
sibsp       -0.0867184  0.0185029  -4.687 3.21e-06 ***
parch       -0.0487147  0.0214741  -2.269 0.023534 *  
fare         0.0003848  0.0003005   1.281 0.200641    
pclass_1     0.1055453  0.0557446   1.893 0.058629 .  
pclass_2     0.1376903  0.0314471   4.378 1.34e-05 ***
sex_M       -0.4270550  0.0253448 -16.850  < 2e-16 ***
embarked_C   0.0585880  0.0319987   1.831 0.067439 .  
embarked_Q   0.1061446  0.0425937   2.492 0.012881 *  
deck_A      -0.3315651  0.1464353  -2.264 0.023797 *  
deck_B      -0.2852592  0.1389479  -2.053 0.040362 *  
deck_C      -0.2951467  0.1350558  -2.185 0.029120 *  
deck_D      -0.3605291  0.1318846  -2.734 0.006386 ** 
deck_E       0.0078459  0.1256544   0.062 0.950226    
deck_F      -0.5745493  0.1193029  -4.816 1.72e-06 ***
sibsp_y      0.1224343  0.0370630   3.303 0.000993 ***
parch_y      0.1573960  0.0479445   3.283 0.001067 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.3436 on 898 degrees of freedom
Multiple R-squared:  0.5124,    Adjusted R-squared:  0.5031 
F-statistic:  55.5 on 17 and 898 DF,  p-value: < 2.2e-16
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(mulvar\_model.ap2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       age      sibsp      parch       fare   pclass_1   pclass_2      sex_M 
  1.380228   2.359204   2.776007   1.908310   4.649205   1.290432   1.145551 
embarked_C embarked_Q     deck_A     deck_B     deck_C     deck_D     deck_E 
  1.379990   1.147247   5.439805   8.740948  13.154666   9.148653  11.598396 
    deck_F    sibsp_y    parch_y 
 26.237760   2.297316   3.213776 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{lmod.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{glm}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(survived) }\SpecialCharTok{\textasciitilde{}}\NormalTok{ ., }\AttributeTok{family =}\NormalTok{ binomial, }\AttributeTok{data =}\NormalTok{ train.ap2)}
\FunctionTok{summary}\NormalTok{(lmod.ap2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}

Call:
glm(formula = as.factor(survived) ~ ., family = binomial, data = train.ap2)

Coefficients:
              Estimate Std. Error z value Pr(>|z|)    
(Intercept)  5.1275081  1.3016899   3.939 8.18e-05 ***
age         -0.0558992  0.0094958  -5.887 3.94e-09 ***
sibsp       -1.0266480  0.2640080  -3.889 0.000101 ***
parch       -0.2791962  0.1939136  -1.440 0.149925    
fare         0.0007343  0.0024042   0.305 0.760042    
pclass_1     1.1421684  0.4862413   2.349 0.018825 *  
pclass_2     1.4015232  0.2992294   4.684 2.82e-06 ***
sex_M       -3.0275901  0.2424805 -12.486  < 2e-16 ***
embarked_C   0.6732550  0.2814737   2.392 0.016762 *  
embarked_Q   1.2284326  0.3679272   3.339 0.000841 ***
deck_A      -2.5767916  1.4219365  -1.812 0.069960 .  
deck_B      -2.2194317  1.4042525  -1.581 0.113991    
deck_C      -2.3552547  1.3682224  -1.721 0.085179 .  
deck_D      -2.9570245  1.3451465  -2.198 0.027928 *  
deck_E       0.4470949  1.3202938   0.339 0.734886    
deck_F      -4.4528239  1.2754924  -3.491 0.000481 ***
sibsp_y      1.3882952  0.3947966   3.516 0.000437 ***
parch_y      1.2304958  0.4199141   2.930 0.003386 ** 
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 1223.12  on 915  degrees of freedom
Residual deviance:  620.68  on 898  degrees of freedom
AIC: 656.68

Number of Fisher Scoring iterations: 6
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{vif}\NormalTok{(lmod.ap2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
       age      sibsp      parch       fare   pclass_1   pclass_2      sex_M 
  1.619429   3.641267   2.989704   1.753639   5.122869   1.534060   1.410059 
embarked_C embarked_Q     deck_A     deck_B     deck_C     deck_D     deck_E 
  1.487757   1.363260   9.852461  13.562280  21.612617  16.823106  13.659175 
    deck_F    sibsp_y    parch_y 
 39.454519   3.482784   3.287406 
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y\_hat\_mulvar\_train.ap2}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(mulvar\_model.ap2, }\AttributeTok{data =}\NormalTok{ train.ap2)}
\NormalTok{predictions\_train.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_mulvar\_train.ap2 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTrain\_mulvar.ap2}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ train.ap2}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{predictions\_train.ap2)}
\NormalTok{linear.train.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTrain\_mulvar.ap2)}

\NormalTok{y\_hat\_mulvar\_test.ap2}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(mulvar\_model.ap2, }\AttributeTok{newdata =}\NormalTok{ test.ap2)}
\NormalTok{predictions\_test.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_mulvar\_test.ap2 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTest\_mulvar.ap2}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ test.ap2}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{predictions\_test.ap2)}
\NormalTok{linear.test.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTest\_mulvar.ap2)}


\NormalTok{y\_hat\_log\_train.ap2}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(lmod.ap2, }\AttributeTok{data =}\NormalTok{ train.ap2)}
\NormalTok{predictions\_log\_train.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_log\_train.ap2 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTrain\_lmod.ap2}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ train.ap2}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{y\_hat\_log\_train.ap2)}
\NormalTok{log.train.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTrain\_mulvar.ap2)}

\NormalTok{y\_hat\_log\_test.ap2}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(lmod.ap2, }\AttributeTok{newdata =}\NormalTok{ test.ap2)}
\NormalTok{predictions\_log\_test.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{ifelse}\NormalTok{(y\_hat\_log\_test.ap2 }\SpecialCharTok{\textgreater{}} \FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{)}
\NormalTok{ModelTest\_lmod.ap2}\OtherTok{\textless{}{-}}\FunctionTok{data.frame}\NormalTok{(}\AttributeTok{obs =}\NormalTok{ test.ap2}\SpecialCharTok{$}\NormalTok{survived, }\AttributeTok{pred=}\NormalTok{predictions\_log\_test.ap2)}
\NormalTok{log.test.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{defaultSummary}\NormalTok{(ModelTest\_lmod.ap2)}


\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(linear.train.ap2,linear.test.ap2,log.train.ap2,log.test.ap2))}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}lrrr@{}}
\toprule\noalign{}
& RMSE & Rsquared & MAE \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
linear.train.ap2 & 0.3909456 & 0.4570397 & 0.1528384 \\
linear.test.ap2 & 0.4040610 & 0.4221825 & 0.1632653 \\
log.train.ap2 & 0.3909456 & 0.4570397 & 0.1528384 \\
log.test.ap2 & 0.4008919 & 0.4212961 & 0.1607143 \\
\end{longtable}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_mulvar\_train.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_train.ap2), }\FunctionTok{as.factor}\NormalTok{(train.ap2}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_mulvar\_train.ap2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 498  77
         1  63 278
                                          
               Accuracy : 0.8472          
                 95% CI : (0.8222, 0.8699)
    No Information Rate : 0.6124          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6757          
                                          
 Mcnemar's Test P-Value : 0.2719          
                                          
              Precision : 0.8152          
                 Recall : 0.7831          
                     F1 : 0.7989          
             Prevalence : 0.3876          
         Detection Rate : 0.3035          
   Detection Prevalence : 0.3723          
      Balanced Accuracy : 0.8354          
                                          
       'Positive' Class : 1               
                                          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_mulvar\_test.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_test.ap2), }\FunctionTok{as.factor}\NormalTok{(test.ap2}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_mulvar\_test.ap2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 215  32
         1  32 113
                                          
               Accuracy : 0.8367          
                 95% CI : (0.7964, 0.8719)
    No Information Rate : 0.6301          
    P-Value [Acc > NIR] : <2e-16          
                                          
                  Kappa : 0.6498          
                                          
 Mcnemar's Test P-Value : 1               
                                          
              Precision : 0.7793          
                 Recall : 0.7793          
                     F1 : 0.7793          
             Prevalence : 0.3699          
         Detection Rate : 0.2883          
   Detection Prevalence : 0.3699          
      Balanced Accuracy : 0.8249          
                                          
       'Positive' Class : 1               
                                          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_log\_train.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_log\_train.ap2), }\FunctionTok{as.factor}\NormalTok{(train.ap2}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_log\_train.ap2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 523 111
         1  38 244
                                          
               Accuracy : 0.8373          
                 95% CI : (0.8118, 0.8607)
    No Information Rate : 0.6124          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6439          
                                          
 Mcnemar's Test P-Value : 3.669e-09       
                                          
              Precision : 0.8652          
                 Recall : 0.6873          
                     F1 : 0.7661          
             Prevalence : 0.3876          
         Detection Rate : 0.2664          
   Detection Prevalence : 0.3079          
      Balanced Accuracy : 0.8098          
                                          
       'Positive' Class : 1               
                                          
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion\_matrix\_log\_test.ap2 }\OtherTok{\textless{}{-}} \FunctionTok{confusionMatrix}\NormalTok{(}\FunctionTok{as.factor}\NormalTok{(predictions\_log\_test.ap2), }\FunctionTok{as.factor}\NormalTok{(test.ap2}\SpecialCharTok{$}\NormalTok{survived),}\AttributeTok{mode=}\StringTok{"prec\_recall"}\NormalTok{, }\AttributeTok{positive =} \StringTok{"1"}\NormalTok{)}
\NormalTok{confusion\_matrix\_log\_test.ap2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 227  43
         1  20 102
                                          
               Accuracy : 0.8393          
                 95% CI : (0.7991, 0.8742)
    No Information Rate : 0.6301          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.6436          
                                          
 Mcnemar's Test P-Value : 0.005576        
                                          
              Precision : 0.8361          
                 Recall : 0.7034          
                     F1 : 0.7640          
             Prevalence : 0.3699          
         Detection Rate : 0.2602          
   Detection Prevalence : 0.3112          
      Balanced Accuracy : 0.8112          
                                          
       'Positive' Class : 1               
                                          
\end{verbatim}

\section*{References}\label{references}
\addcontentsline{toc}{section}{References}

\phantomsection\label{refs}
\begin{CSLReferences}{1}{0}
\bibitem[\citeproctext]{ref-noaa2023}
National Oceanic and Atmospheric Administration (NOAA). (2023).
\emph{RMS titanic -- history and significance}.
\url{https://www.noaa.gov/office-of-general-counsel/gc-international-section/rms-titanic-history-and-significance}

\bibitem[\citeproctext]{ref-statology2025}
Statology. (2025). \emph{How to measure correlation between categorical
variables}.
\url{https://www.statology.org/correlation-between-categorical-variables/}

\end{CSLReferences}




\end{document}
